{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMXih+Jik9fH7Q6LDcGJesD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dohi1004/AI-teamProject-brailleTranslation/blob/main/AI_FinalProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***\n",
        "# **AI Team Project Final Presentation**\n",
        "\n",
        "### **Team 6**\n",
        "\n",
        "16102269 Kim Jong Gyu\n",
        "\n",
        "19102095 Lee Do Hui\n",
        "***\n",
        "\n"
      ],
      "metadata": {
        "id": "VpRu5GlOLhbE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Motivation For The Proeject**\n",
        "* Similar to general language, braille is different according to the world.\n",
        "* T\n",
        "\n",
        "시각 장애인이 외국어로 되어 있는 점자를 읽어야 하는 경우 해당 나라 언어의 점자를 배운 적이 없다면 읽을 수 없습니다. 따라서, 외국어 점자를 모국어 음성으로 변환해주는 application을 만들고자 합니다."
      ],
      "metadata": {
        "id": "xz2a97bVLqBD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Problem Description**\n",
        "Here, we suppose the use case as follows. Here, we use similar word order languages (English, French) because of using basic NMT model.\n",
        "\n",
        "1) English blind \n",
        "\n",
        "2) French\n",
        "\n",
        "1. English blind write braille \n",
        "2. Translate English braille to English (with Braille Translation)\n",
        "3. Translate English to French (with Neural Machine Translation)\n",
        "\n",
        "\n",
        "**Braille Translation and Language Translation**\n",
        "\n",
        "### 1) Braille Translation\n",
        "\n",
        "Translate English braille to English.\n",
        "\n",
        "### 2) Language Translation\n",
        "\n",
        "Translate English to French.\n",
        "\n",
        "**Finally, our application can translate other language's braille to target person's language by connecting those two models.** \n",
        "\n"
      ],
      "metadata": {
        "id": "sXhdwLhc6aJi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Data Description**\n",
        "\n",
        "### **Braille Translation**\n",
        "*   ~~Preferentially, I use braille notation in English dataset in Kaggle~~\n",
        "  *   ~~Reference : https://www.kaggle.com/code/kwisatzhaderach/braille-classifier-keras/data~~\n",
        "\n",
        "### **Neural Machine Translation**\n",
        "\n",
        "*   For neural machine translation model, we used dataset comprised of French phrases and their English counterparts. The dataset is available from the http://www.manythings.org/anki/, with examples drawn from the Tatoeba Project.\n",
        "\n",
        "<img src = \"https://drive.google.com/uc?id=1zgHVKVLXsjyD4re6bWE5baV0q71J4yQo\" height = 250 width = 500>\n",
        "\n",
        "* The fra.txt file contains pairs of English to French phrases, one pair per line with a tab separating the language. Total pairs of sentences are 197,463.\n",
        "\n",
        "<img src = \"https://drive.google.com/uc?id=1-WO41TvUqFickYyjN298293hUtBSZRUs\" height = 150 width = 600>\n",
        "\n",
        "------------------\n",
        "Preprocessing process of each data is explained in 5. Implementation Details\n",
        "\n",
        "------------------"
      ],
      "metadata": {
        "id": "8U0pwhGVLr70"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4.Model Architecture**\n",
        "\n",
        "### 1) Model 1: Convolutional Neural Network\n",
        "\n",
        "a model consisting of ~~~~> \n",
        "\n",
        "### 2) Model 2: Seq2Seq model  - LSTM & GRU\n",
        "\n",
        "Encoder-decoder based model. By comparing the performance of LSTM and GRU model each, we decide to use ~~ model. "
      ],
      "metadata": {
        "id": "s9FaYZLN_vex"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5. Implementation Details**"
      ],
      "metadata": {
        "id": "PzhphPvU7WkT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Part1. Braille Translation Model** "
      ],
      "metadata": {
        "id": "xOVbGzraM_qM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Hyperparameter Selection Process**"
      ],
      "metadata": {
        "id": "ODmKZsoCOiZO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  **Part2. NMT model (English -> French)**\n"
      ],
      "metadata": {
        "id": "sqeK8VzxOlmd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install rouge"
      ],
      "metadata": {
        "id": "nXd_UTKWVQWk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abc03591-2d1f-4aa6-801d-68623874baa4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting rouge\n",
            "  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from rouge) (1.15.0)\n",
            "Installing collected packages: rouge\n",
            "Successfully installed rouge-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Data and preprocessing**"
      ],
      "metadata": {
        "id": "7OwAeOrQpRny"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/') "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NlZ0kYVb8ioM",
        "outputId": "620546d8-0629-4510-c248-074121601e8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv(\"./gdrive/MyDrive/AI/teamProject/fra.txt\", delimiter = \"\\t\")\n",
        "data.columns = [\"en\", \"fr\", \"cc\"]\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "LLk6wspjpG2Q",
        "outputId": "180d1938-0953-42cd-d2b2-0568fa395d3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                       en  \\\n",
              "0                                                     Go.   \n",
              "1                                                     Go.   \n",
              "2                                                     Go.   \n",
              "3                                                     Hi.   \n",
              "4                                                     Hi.   \n",
              "...                                                   ...   \n",
              "197457  A carbon footprint is the amount of carbon dio...   \n",
              "197458  Death is something that we're often discourage...   \n",
              "197459  Since there are usually multiple websites on a...   \n",
              "197460  If someone who doesn't know your background sa...   \n",
              "197461  It may be impossible to get a completely error...   \n",
              "\n",
              "                                                       fr  \\\n",
              "0                                                 Marche.   \n",
              "1                                              En route !   \n",
              "2                                                 Bouge !   \n",
              "3                                                 Salut !   \n",
              "4                                                  Salut.   \n",
              "...                                                   ...   \n",
              "197457  Une empreinte carbone est la somme de pollutio...   \n",
              "197458  La mort est une chose qu'on nous décourage sou...   \n",
              "197459  Puisqu'il y a de multiples sites web sur chaqu...   \n",
              "197460  Si quelqu'un qui ne connaît pas vos antécédent...   \n",
              "197461  Il est peut-être impossible d'obtenir un Corpu...   \n",
              "\n",
              "                                                       cc  \n",
              "0       CC-BY 2.0 (France) Attribution: tatoeba.org #2...  \n",
              "1       CC-BY 2.0 (France) Attribution: tatoeba.org #2...  \n",
              "2       CC-BY 2.0 (France) Attribution: tatoeba.org #2...  \n",
              "3       CC-BY 2.0 (France) Attribution: tatoeba.org #5...  \n",
              "4       CC-BY 2.0 (France) Attribution: tatoeba.org #5...  \n",
              "...                                                   ...  \n",
              "197457  CC-BY 2.0 (France) Attribution: tatoeba.org #1...  \n",
              "197458  CC-BY 2.0 (France) Attribution: tatoeba.org #1...  \n",
              "197459  CC-BY 2.0 (France) Attribution: tatoeba.org #9...  \n",
              "197460  CC-BY 2.0 (France) Attribution: tatoeba.org #9...  \n",
              "197461  CC-BY 2.0 (France) Attribution: tatoeba.org #2...  \n",
              "\n",
              "[197462 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b43201d9-9fea-4e64-a935-68fc7943f4b2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>en</th>\n",
              "      <th>fr</th>\n",
              "      <th>cc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Go.</td>\n",
              "      <td>Marche.</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Go.</td>\n",
              "      <td>En route !</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Go.</td>\n",
              "      <td>Bouge !</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Hi.</td>\n",
              "      <td>Salut !</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #5...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Hi.</td>\n",
              "      <td>Salut.</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #5...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>197457</th>\n",
              "      <td>A carbon footprint is the amount of carbon dio...</td>\n",
              "      <td>Une empreinte carbone est la somme de pollutio...</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>197458</th>\n",
              "      <td>Death is something that we're often discourage...</td>\n",
              "      <td>La mort est une chose qu'on nous décourage sou...</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>197459</th>\n",
              "      <td>Since there are usually multiple websites on a...</td>\n",
              "      <td>Puisqu'il y a de multiples sites web sur chaqu...</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #9...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>197460</th>\n",
              "      <td>If someone who doesn't know your background sa...</td>\n",
              "      <td>Si quelqu'un qui ne connaît pas vos antécédent...</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #9...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>197461</th>\n",
              "      <td>It may be impossible to get a completely error...</td>\n",
              "      <td>Il est peut-être impossible d'obtenir un Corpu...</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>197462 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b43201d9-9fea-4e64-a935-68fc7943f4b2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b43201d9-9fea-4e64-a935-68fc7943f4b2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b43201d9-9fea-4e64-a935-68fc7943f4b2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import shutil\n",
        "import zipfile\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import unicodedata\n",
        "import urllib3\n",
        "from tensorflow.keras.layers import Embedding, GRU, Dense\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ],
      "metadata": {
        "id": "5P9wLfNv8hni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def to_ascii(s):\n",
        "    # delete accent in French\n",
        "    # EX) : 'déjà diné' -> deja dine\n",
        "    return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
        "                   if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "def preprocess_sentence(sent):\n",
        "    # Call accent deletion function\n",
        "    sent = to_ascii(sent.lower())\n",
        "    \n",
        "    # Add blank between word and punctuation \n",
        "    # ex) \"I am a student.\" => \"I am a student .\"\n",
        "    sent = re.sub(r\"([?.!,¿])\", r\" \\1\", sent)\n",
        "    \n",
        "    # Except (a-z, A-Z, \".\", \"?\", \"!\", \",\"), transform others to blank\n",
        "    sent = re.sub(r\"[^a-zA-Z!.?]+\", r\" \", sent)\n",
        "    \n",
        "    # Transform multiple blanks to one blank\n",
        "    sent = re.sub(r\"\\s+\", \" \", sent)\n",
        "    \n",
        "    return sent"
      ],
      "metadata": {
        "id": "x0WkR49X9Qq8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing Test\n",
        "en_sent = u\"Have you had dinner?\"\n",
        "fr_sent = u\"Avez-vous déjà diné?\"\n",
        "\n",
        "print('Before preprocessing English sentence :', en_sent)\n",
        "print('After preprocessing English sentence :',preprocess_sentence(en_sent))\n",
        "print('Before preprocessing French sentence :', fr_sent)\n",
        "print('After preprocessing French sentence :', preprocess_sentence(fr_sent))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJdUEWO39Sfq",
        "outputId": "7f5319c2-817b-4a76-91d9-7a182cdc6880"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before preprocessing English sentence : Have you had dinner?\n",
            "After preprocessing English sentence : have you had dinner ?\n",
            "Before preprocessing French sentence : Avez-vous déjà diné?\n",
            "After preprocessing French sentence : avez vous deja dine ?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_preprocessed_data():\n",
        "    encoder_input, decoder_input, decoder_target = [], [], []\n",
        "    src_seqlen = 0\n",
        "    tar_seqlen = 0\n",
        "    with open(\"./gdrive/MyDrive/AI/teamProject/fra.txt\", \"r\", encoding='UTF-8') as lines:\n",
        "        for i, line in enumerate(lines):\n",
        "            # split source data and target data \n",
        "            src_line, tar_line, _ = line.strip().split('\\t')\n",
        "            \n",
        "            # preprocess source data\n",
        "            preprocessed_sen = preprocess_sentence(src_line)\n",
        "            src_line = [w for w in preprocessed_sen.split()]\n",
        "            for w in preprocessed_sen.split():\n",
        "              if len(w) > src_seqlen:\n",
        "                src_seqlen = len(w)\n",
        "            \n",
        "            # preprocess target data\n",
        "            tar_line = preprocess_sentence(tar_line)\n",
        "            for w in tar_line.split():\n",
        "              if len(w) > tar_seqlen:\n",
        "                tar_seqlen = len(w)\n",
        "                \n",
        "            tar_line_in = [w for w in (\"<sos> \" + tar_line).split()]\n",
        "            tar_line_out = [w for w in (tar_line + \" <eos>\").split()]\n",
        "            \n",
        "            encoder_input.append(src_line)\n",
        "            decoder_input.append(tar_line_in)\n",
        "            decoder_target.append(tar_line_out)\n",
        "            \n",
        "            if i == num_samples - 1:\n",
        "                break\n",
        "        \n",
        "    return encoder_input, decoder_input, decoder_target, src_seqlen, tar_seqlen"
      ],
      "metadata": {
        "id": "SU0FM-yw9T_K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "length = 0\n",
        "with open(\"./gdrive/MyDrive/AI/teamProject/fra.txt\", \"r\", encoding='UTF-8') as lines:\n",
        "        for i, line in enumerate(lines):\n",
        "            length+=1\n",
        "print(length)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDq4FDWS9UZo",
        "outputId": "2f8f638f-f175-4789-f347-5c0d77359151"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "197463\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_samples = 70000"
      ],
      "metadata": {
        "id": "Kx4H1PvY9sdC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sents_en_in, sents_fra_in, sents_fra_out, src_seqlen, tar_seqlen = load_preprocessed_data()\n",
        "print('Input of Encoder :',sents_en_in[:5])\n",
        "print('Input of Decoder :',sents_fra_in[:5])\n",
        "print('Label of Decoder :',sents_fra_out[:5])\n",
        "print(src_seqlen)\n",
        "print(tar_seqlen)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EEOxVdso9S4m",
        "outputId": "738db774-e777-4294-ad2f-f6495a43b46a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input of Encoder : [['go', '.'], ['go', '.'], ['go', '.'], ['go', '.'], ['hi', '.']]\n",
            "Input of Decoder : [['<sos>', 'va', '!'], ['<sos>', 'marche', '.'], ['<sos>', 'en', 'route', '!'], ['<sos>', 'bouge', '!'], ['<sos>', 'salut', '!']]\n",
            "Label of Decoder : [['va', '!', '<eos>'], ['marche', '.', '<eos>'], ['en', 'route', '!', '<eos>'], ['bouge', '!', '<eos>'], ['salut', '!', '<eos>']]\n",
            "16\n",
            "18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_en = Tokenizer(filters=\"\", lower=False)\n",
        "tokenizer_en.fit_on_texts(sents_en_in)\n",
        "encoder_input = tokenizer_en.texts_to_sequences(sents_en_in)\n",
        "encoder_input = pad_sequences(encoder_input, padding=\"post\")\n",
        "\n",
        "tokenizer_fra = Tokenizer(filters=\"\", lower=False)\n",
        "tokenizer_fra.fit_on_texts(sents_fra_in)\n",
        "tokenizer_fra.fit_on_texts(sents_fra_out)\n",
        "\n",
        "decoder_input = tokenizer_fra.texts_to_sequences(sents_fra_in)\n",
        "decoder_input = pad_sequences(decoder_input, padding=\"post\")\n",
        "\n",
        "decoder_target = tokenizer_fra.texts_to_sequences(sents_fra_out)\n",
        "decoder_target = pad_sequences(decoder_target, padding=\"post\")"
      ],
      "metadata": {
        "id": "vR3hqwy79lSe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Input of Encoder Shape :',encoder_input.shape)\n",
        "print('Input of Decoder Shape :',decoder_input.shape)\n",
        "print('Label of Decoder Shape :',decoder_target.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lErUV8Rn9xo1",
        "outputId": "713aeabb-3d57-4985-bef4-a30af5ed17ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input of Encoder Shape : (70000, 9)\n",
            "Input of Decoder Shape : (70000, 17)\n",
            "Label of Decoder Shape : (70000, 17)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "src_vocab_size = len(tokenizer_en.word_index) + 1\n",
        "tar_vocab_size = len(tokenizer_fra.word_index) + 1\n",
        "print(\"Size of English word set : {:d}, Size of French word set : {:d}\".format(src_vocab_size, tar_vocab_size))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fg6RgZNr9z3W",
        "outputId": "e9e7eb24-e8dc-4ab0-89aa-0aa188c31ca7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of English word set : 7241, Size of French word set : 12336\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "src_to_index = tokenizer_en.word_index\n",
        "index_to_src = tokenizer_en.index_word\n",
        "tar_to_index = tokenizer_fra.word_index\n",
        "index_to_tar = tokenizer_fra.index_word"
      ],
      "metadata": {
        "id": "484gZQKC903s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "indices = np.arange(encoder_input.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "print('Random Sequence :',indices)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YT6KNypQ91_H",
        "outputId": "873cd6aa-f1c0-40a3-b464-8d0268ea99c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Sequence : [26140 32868 26191 ... 35678 11235 25854]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_input = encoder_input[indices]\n",
        "decoder_input = decoder_input[indices]\n",
        "decoder_target = decoder_target[indices]"
      ],
      "metadata": {
        "id": "Tx2Ty3Td93G6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(encoder_input[30997])\n",
        "print(decoder_input[30997])\n",
        "print(decoder_target[30997])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLFLtof494In",
        "outputId": "abaf2c00-8f0d-4a49-a9cd-e1418c9248f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  19    7 2637    1    0    0    0    0    0]\n",
            "[  2  24   6 286   1   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            "[ 24   6 286   1   3   0   0   0   0   0   0   0   0   0   0   0   0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_of_val = int(num_samples*0.1)\n",
        "print('Number of validation data :',n_of_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQnAwAoP94_z",
        "outputId": "ea8b0266-bfa6-41f1-e903-d47e34fbb963"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of validation data : 7000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_input_train = encoder_input[:-n_of_val]\n",
        "decoder_input_train = decoder_input[:-n_of_val]\n",
        "decoder_target_train = decoder_target[:-n_of_val]\n",
        "\n",
        "encoder_input_test = encoder_input[-n_of_val:]\n",
        "decoder_input_test = decoder_input[-n_of_val:]\n",
        "decoder_target_test = decoder_target[-n_of_val:]"
      ],
      "metadata": {
        "id": "CEdPf9RJ96Bk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Shape of training source data :',encoder_input_train.shape)\n",
        "print('Shape of training target data :',decoder_input_train.shape)\n",
        "print('Shape of trainig target label data :',decoder_target_train.shape)\n",
        "print('Shape of test source data :',encoder_input_test.shape)\n",
        "print('Shape of test target data :',decoder_input_test.shape)\n",
        "print('Shape of test target label data :',decoder_target_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UfYr08J397LQ",
        "outputId": "512d7552-fb1b-4456-cfd8-c871bbb3cb22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of training source data : (63000, 9)\n",
            "Shape of training target data : (63000, 17)\n",
            "Shape of trainig target label data : (63000, 17)\n",
            "Shape of test source data : (7000, 9)\n",
            "Shape of test target data : (7000, 17)\n",
            "Shape of test target label data : (7000, 17)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **LSTM model**"
      ],
      "metadata": {
        "id": "SCoN6g7Wkphi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Masking\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import optimizers\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint"
      ],
      "metadata": {
        "id": "_Fuxi-5R98K4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Hyperparameter Tuning**"
      ],
      "metadata": {
        "id": "3mGtJAw7kuI8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def LSTM_Model(embedding_dim, hidden_units, lr, b1, b2, batchsize, encoder_dropout, decoder_dropout):\n",
        "  encoder_inputs = Input(shape=(None,))\n",
        "  enc_emb = Embedding(src_vocab_size, embedding_dim)(encoder_inputs) # Embedding layer\n",
        "  enc_masking = Masking(mask_value=0.0)(enc_emb) # Exclude padding 0 in operation\n",
        "  encoder_lstm = LSTM(hidden_units, return_state=True, dropout=encoder_dropout) # To return state value\n",
        "  encoder_outputs, state_h, state_c = encoder_lstm(enc_masking) # Return hidden state and cell state\n",
        "  encoder_states = [state_h, state_c] # Save encoder's hidden state and cell state\n",
        "\n",
        "  # Decoder\n",
        "  decoder_inputs = Input(shape=(None,))\n",
        "  dec_emb_layer = Embedding(tar_vocab_size, hidden_units) # Embedding layer\n",
        "  dec_emb = dec_emb_layer(decoder_inputs) # exclude padding 0 in operation\n",
        "  dec_masking = Masking(mask_value=0.0)(dec_emb)\n",
        "\n",
        "  # To return state value, return_state = True\n",
        "  # To predict word for every time step, return_sequences = True\n",
        "  decoder_lstm = LSTM(hidden_units, return_sequences=True, return_state=True, dropout=decoder_dropout) \n",
        "\n",
        "  # Use encoder's hidden state as initial hidden state \n",
        "  decoder_outputs, _, _ = decoder_lstm(dec_masking,\n",
        "                                      initial_state=encoder_states)\n",
        "\n",
        "  # predict word bsaed on softmax activation function for all results from every time step\n",
        "  decoder_dense = Dense(tar_vocab_size, activation='softmax')\n",
        "  decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "  # Model's input and output \n",
        "  model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "  model.compile(optimizer=optimizers.Adam(learning_rate=lr, beta_1=b1, beta_2=b2), loss='sparse_categorical_crossentropy', metrics=['acc'])\n",
        "\n",
        "  history = model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train, \\\n",
        "          validation_data=([encoder_input_test, decoder_input_test], decoder_target_test),\n",
        "          batch_size=batchsize, callbacks=[EarlyStopping(monitor='val_loss', patience = 3)], epochs=10) # for testing, we use epochs = 10 \n",
        "\n",
        "  return history.history['val_loss'][-1]"
      ],
      "metadata": {
        "id": "IRoJKkCp99Mj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_hyper_param(n_iteration):\n",
        "  hyper_param = []  # learning_rate, n_hidden, timestep, epochs\n",
        "  for i in range(n_iteration):\n",
        "    current_params = []\n",
        "    # We use adam optimizer, so we tune learning rate\n",
        "    current_params.append(np.random.uniform(0,0.1)) # learning rate \n",
        "    current_params.append(np.random.uniform(0.5,0.999)) # b1 (from Momentum)\n",
        "    current_params.append(np.random.uniform(0.5,0.999)) # b2 (from RMSProp)\n",
        "    current_params.append(np.random.randint(1,513)) # hidden units \n",
        "    current_params.append(np.random.randint(32,513)) # batch_size\n",
        "    current_params.append(np.random.randint(50,300)) # embedding dimension\n",
        "    current_params.append(np.random.uniform(0,0.5)) # encoder dropout\n",
        "    current_params.append(np.random.uniform(0,0.5)) # decoder dropout\n",
        "    hyper_param.append(current_params)\n",
        "  return hyper_param\n",
        "\n",
        "hyper_parameter = get_hyper_param(30)\n",
        "train_loss, val_loss = list(), list()\n",
        "best_params = []\n",
        "\n",
        "min_val_loss = 999\n",
        "for alpha, b1, b2, hidden_units, batch_size, embedding_dim, en_dropout, de_dropout in hyper_parameter:\n",
        "  print('lr',alpha, 'b1', b1, 'b2', b2, 'n_hiddens', hidden_units,'batch_size', batch_size, 'embedding_dim', embedding_dim, \n",
        "        'en_dropout',  en_dropout, 'de_dropout', de_dropout)\n",
        "\n",
        "  # model 정의 (model.add ~ model.compile 까지)\n",
        "  current_val_loss = LSTM_Model(embedding_dim, hidden_units, alpha, b1, b2, batch_size, en_dropout, de_dropout)\n",
        "\n",
        "  if current_val_loss < min_val_loss:\n",
        "    min_val_loss = current_val_loss\n",
        "    best_params = [alpha, b1, b2, hidden_units, batch_size, embedding_dim, en_dropout, de_dropout]\n",
        "    print('best_params',best_params)\n",
        "  \n",
        "print('final best params',best_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-ic7p5kxBA4",
        "outputId": "219ae8b9-b226-4b63-ce29-979e14b44ae0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lr 0.06270461188149924 b1 0.843482643498749 b2 0.8925307649479214 n_hiddens 376 batch_size 455 embedding_dim 225 en_dropout 0.25149046826372107 de_dropout 0.28754374782314557\n",
            "Epoch 1/10\n",
            "139/139 [==============================] - 30s 161ms/step - loss: 1.9090 - acc: 0.7286 - val_loss: 1.3475 - val_acc: 0.7799\n",
            "Epoch 2/10\n",
            "139/139 [==============================] - 19s 140ms/step - loss: 1.2717 - acc: 0.7855 - val_loss: 1.2778 - val_acc: 0.7887\n",
            "Epoch 3/10\n",
            "139/139 [==============================] - 20s 141ms/step - loss: 1.2140 - acc: 0.7914 - val_loss: 1.2685 - val_acc: 0.7928\n",
            "Epoch 4/10\n",
            "139/139 [==============================] - 19s 140ms/step - loss: 1.1871 - acc: 0.7942 - val_loss: 1.2826 - val_acc: 0.7924\n",
            "Epoch 5/10\n",
            "139/139 [==============================] - 19s 139ms/step - loss: 1.1731 - acc: 0.7954 - val_loss: 1.2741 - val_acc: 0.7956\n",
            "Epoch 6/10\n",
            "139/139 [==============================] - 19s 139ms/step - loss: 1.1693 - acc: 0.7960 - val_loss: 1.2842 - val_acc: 0.7953\n",
            "best_params [0.06270461188149924, 0.843482643498749, 0.8925307649479214, 376, 455, 225, 0.25149046826372107, 0.28754374782314557]\n",
            "lr 0.02118024944924988 b1 0.9389073612586014 b2 0.6943851192685523 n_hiddens 180 batch_size 483 embedding_dim 267 en_dropout 0.26315532566808136 de_dropout 0.45960397092538496\n",
            "Epoch 1/10\n",
            "131/131 [==============================] - 23s 126ms/step - loss: 4.7951 - acc: 0.6921 - val_loss: 5.7771 - val_acc: 0.7042\n",
            "Epoch 2/10\n",
            "131/131 [==============================] - 14s 109ms/step - loss: 11.5435 - acc: 0.6752 - val_loss: 10.9803 - val_acc: 0.6951\n",
            "Epoch 3/10\n",
            "131/131 [==============================] - 15s 112ms/step - loss: 27.6251 - acc: 0.6610 - val_loss: 19.6772 - val_acc: 0.6848\n",
            "Epoch 4/10\n",
            "131/131 [==============================] - 14s 107ms/step - loss: 27.9606 - acc: 0.6590 - val_loss: 15.0826 - val_acc: 0.6867\n",
            "lr 0.03532356910620672 b1 0.6991163352213629 b2 0.5106045388120525 n_hiddens 31 batch_size 428 embedding_dim 189 en_dropout 0.025871393417969957 de_dropout 0.11966258058417795\n",
            "Epoch 1/10\n",
            "148/148 [==============================] - 21s 85ms/step - loss: 2.1273 - acc: 0.6990 - val_loss: 1.5400 - val_acc: 0.7493\n",
            "Epoch 2/10\n",
            "148/148 [==============================] - 10s 71ms/step - loss: 1.4382 - acc: 0.7627 - val_loss: 1.3728 - val_acc: 0.7709\n",
            "Epoch 3/10\n",
            "148/148 [==============================] - 10s 68ms/step - loss: 1.2985 - acc: 0.7808 - val_loss: 1.2627 - val_acc: 0.7897\n",
            "Epoch 4/10\n",
            "148/148 [==============================] - 10s 69ms/step - loss: 1.2128 - acc: 0.7962 - val_loss: 1.2211 - val_acc: 0.7977\n",
            "Epoch 5/10\n",
            "148/148 [==============================] - 10s 68ms/step - loss: 1.1712 - acc: 0.8026 - val_loss: 1.1976 - val_acc: 0.8020\n",
            "Epoch 6/10\n",
            "148/148 [==============================] - 10s 68ms/step - loss: 1.1501 - acc: 0.8057 - val_loss: 1.1824 - val_acc: 0.8044\n",
            "Epoch 7/10\n",
            "148/148 [==============================] - 11s 72ms/step - loss: 1.1391 - acc: 0.8079 - val_loss: 1.1858 - val_acc: 0.8046\n",
            "Epoch 8/10\n",
            "148/148 [==============================] - 10s 68ms/step - loss: 1.1317 - acc: 0.8094 - val_loss: 1.1775 - val_acc: 0.8071\n",
            "Epoch 9/10\n",
            "148/148 [==============================] - 10s 68ms/step - loss: 1.1240 - acc: 0.8106 - val_loss: 1.1830 - val_acc: 0.8075\n",
            "Epoch 10/10\n",
            "148/148 [==============================] - 10s 68ms/step - loss: 1.1185 - acc: 0.8112 - val_loss: 1.1884 - val_acc: 0.8047\n",
            "best_params [0.03532356910620672, 0.6991163352213629, 0.5106045388120525, 31, 428, 189, 0.025871393417969957, 0.11966258058417795]\n",
            "lr 0.004802586925210162 b1 0.9034282275741946 b2 0.5912046730992582 n_hiddens 347 batch_size 75 embedding_dim 197 en_dropout 0.09069297020865585 de_dropout 0.3571965711563737\n",
            "Epoch 1/10\n",
            "840/840 [==============================] - 41s 42ms/step - loss: 47.3274 - acc: 0.5939 - val_loss: 40.8621 - val_acc: 0.6827\n",
            "Epoch 2/10\n",
            "840/840 [==============================] - 33s 39ms/step - loss: 28.2203 - acc: 0.6869 - val_loss: 20.1261 - val_acc: 0.7027\n",
            "Epoch 3/10\n",
            "840/840 [==============================] - 33s 39ms/step - loss: 17.9412 - acc: 0.6983 - val_loss: 14.8258 - val_acc: 0.7074\n",
            "Epoch 4/10\n",
            "840/840 [==============================] - 33s 39ms/step - loss: 14.3908 - acc: 0.6995 - val_loss: 12.5988 - val_acc: 0.7119\n",
            "Epoch 5/10\n",
            "840/840 [==============================] - 33s 39ms/step - loss: 12.5363 - acc: 0.7025 - val_loss: 10.9532 - val_acc: 0.7096\n",
            "Epoch 6/10\n",
            "840/840 [==============================] - 33s 39ms/step - loss: 11.0241 - acc: 0.7048 - val_loss: 9.7266 - val_acc: 0.7124\n",
            "Epoch 7/10\n",
            "840/840 [==============================] - 34s 40ms/step - loss: 9.6425 - acc: 0.7064 - val_loss: 8.6794 - val_acc: 0.7161\n",
            "Epoch 8/10\n",
            "840/840 [==============================] - 34s 40ms/step - loss: 8.8936 - acc: 0.7076 - val_loss: 8.1400 - val_acc: 0.7189\n",
            "Epoch 9/10\n",
            "840/840 [==============================] - 35s 41ms/step - loss: 7.9552 - acc: 0.7092 - val_loss: 7.3166 - val_acc: 0.7167\n",
            "Epoch 10/10\n",
            "840/840 [==============================] - 36s 43ms/step - loss: 7.5176 - acc: 0.7102 - val_loss: 6.7090 - val_acc: 0.7203\n",
            "lr 0.007884927954053279 b1 0.9902412478808713 b2 0.9118407790180642 n_hiddens 386 batch_size 63 embedding_dim 167 en_dropout 0.19009677049365437 de_dropout 0.45053422893100076\n",
            "Epoch 1/10\n",
            "1000/1000 [==============================] - 54s 48ms/step - loss: 24.4141 - acc: 0.6873 - val_loss: 93.1671 - val_acc: 0.5327\n",
            "Epoch 2/10\n",
            "1000/1000 [==============================] - 43s 43ms/step - loss: 238.8297 - acc: 0.5407 - val_loss: 200.5516 - val_acc: 0.5119\n",
            "Epoch 3/10\n",
            "1000/1000 [==============================] - 43s 43ms/step - loss: 427.3808 - acc: 0.5085 - val_loss: 337.5587 - val_acc: 0.6407\n",
            "Epoch 4/10\n",
            "1000/1000 [==============================] - 42s 42ms/step - loss: 537.8705 - acc: 0.4848 - val_loss: 327.3697 - val_acc: 0.6251\n",
            "lr 0.09523313337605821 b1 0.6918414557475971 b2 0.870946217502218 n_hiddens 400 batch_size 205 embedding_dim 191 en_dropout 0.2421933926534539 de_dropout 0.048646705756616504\n",
            "Epoch 1/10\n",
            "308/308 [==============================] - 40s 96ms/step - loss: 2.1461 - acc: 0.7245 - val_loss: 1.6466 - val_acc: 0.7559\n",
            "Epoch 2/10\n",
            "308/308 [==============================] - 27s 87ms/step - loss: 1.6281 - acc: 0.7584 - val_loss: 1.6918 - val_acc: 0.7595\n",
            "Epoch 3/10\n",
            "308/308 [==============================] - 27s 86ms/step - loss: 1.6613 - acc: 0.7608 - val_loss: 1.7405 - val_acc: 0.7580\n",
            "Epoch 4/10\n",
            "308/308 [==============================] - 26s 85ms/step - loss: 1.6841 - acc: 0.7651 - val_loss: 1.8078 - val_acc: 0.7674\n",
            "lr 0.08857063677568827 b1 0.7265080871745688 b2 0.6628457134279763 n_hiddens 372 batch_size 334 embedding_dim 189 en_dropout 0.4249982088943396 de_dropout 0.3398478068941738\n",
            "Epoch 1/10\n",
            "189/189 [==============================] - 32s 123ms/step - loss: 3.7367 - acc: 0.7050 - val_loss: 1.5900 - val_acc: 0.7657\n",
            "Epoch 2/10\n",
            "189/189 [==============================] - 20s 107ms/step - loss: 1.5847 - acc: 0.7706 - val_loss: 1.6171 - val_acc: 0.7728\n",
            "Epoch 3/10\n",
            "189/189 [==============================] - 20s 107ms/step - loss: 1.6355 - acc: 0.7723 - val_loss: 1.6590 - val_acc: 0.7752\n",
            "Epoch 4/10\n",
            "189/189 [==============================] - 20s 108ms/step - loss: 1.6976 - acc: 0.7729 - val_loss: 1.7277 - val_acc: 0.7767\n",
            "lr 0.0028760899584410193 b1 0.7334312865588856 b2 0.9341215051090186 n_hiddens 48 batch_size 192 embedding_dim 96 en_dropout 0.3086579782727112 de_dropout 0.49606742902546846\n",
            "Epoch 1/10\n",
            "329/329 [==============================] - 25s 54ms/step - loss: 2.3701 - acc: 0.6782 - val_loss: 1.5742 - val_acc: 0.7502\n",
            "Epoch 2/10\n",
            "329/329 [==============================] - 16s 48ms/step - loss: 1.4242 - acc: 0.7722 - val_loss: 1.3342 - val_acc: 0.7857\n",
            "Epoch 3/10\n",
            "329/329 [==============================] - 15s 46ms/step - loss: 1.2487 - acc: 0.7955 - val_loss: 1.2044 - val_acc: 0.8043\n",
            "Epoch 4/10\n",
            "329/329 [==============================] - 14s 44ms/step - loss: 1.1464 - acc: 0.8087 - val_loss: 1.1237 - val_acc: 0.8141\n",
            "Epoch 5/10\n",
            "329/329 [==============================] - 16s 50ms/step - loss: 1.0751 - acc: 0.8171 - val_loss: 1.0709 - val_acc: 0.8197\n",
            "Epoch 6/10\n",
            "329/329 [==============================] - 15s 45ms/step - loss: 1.0205 - acc: 0.8232 - val_loss: 1.0251 - val_acc: 0.8253\n",
            "Epoch 7/10\n",
            "329/329 [==============================] - 14s 44ms/step - loss: 0.9763 - acc: 0.8284 - val_loss: 0.9852 - val_acc: 0.8310\n",
            "Epoch 8/10\n",
            "329/329 [==============================] - 15s 45ms/step - loss: 0.9381 - acc: 0.8332 - val_loss: 0.9549 - val_acc: 0.8356\n",
            "Epoch 9/10\n",
            "329/329 [==============================] - 15s 45ms/step - loss: 0.9056 - acc: 0.8373 - val_loss: 0.9281 - val_acc: 0.8395\n",
            "Epoch 10/10\n",
            "329/329 [==============================] - 15s 46ms/step - loss: 0.8772 - acc: 0.8410 - val_loss: 0.9062 - val_acc: 0.8423\n",
            "best_params [0.0028760899584410193, 0.7334312865588856, 0.9341215051090186, 48, 192, 96, 0.3086579782727112, 0.49606742902546846]\n",
            "lr 0.04238064913974372 b1 0.829922237961483 b2 0.8271039498988201 n_hiddens 185 batch_size 391 embedding_dim 170 en_dropout 0.2392713682353102 de_dropout 0.2268610592144788\n",
            "Epoch 1/10\n",
            "162/162 [==============================] - 26s 116ms/step - loss: 1.7773 - acc: 0.7336 - val_loss: 1.2973 - val_acc: 0.7786\n",
            "Epoch 2/10\n",
            "162/162 [==============================] - 16s 98ms/step - loss: 1.2114 - acc: 0.7892 - val_loss: 1.1852 - val_acc: 0.7972\n",
            "Epoch 3/10\n",
            "162/162 [==============================] - 15s 95ms/step - loss: 1.1253 - acc: 0.8020 - val_loss: 1.1646 - val_acc: 0.8036\n",
            "Epoch 4/10\n",
            "162/162 [==============================] - 16s 96ms/step - loss: 1.0940 - acc: 0.8063 - val_loss: 1.1693 - val_acc: 0.8052\n",
            "Epoch 5/10\n",
            "162/162 [==============================] - 16s 96ms/step - loss: 1.0787 - acc: 0.8086 - val_loss: 1.1743 - val_acc: 0.8056\n",
            "Epoch 6/10\n",
            "162/162 [==============================] - 15s 94ms/step - loss: 1.0697 - acc: 0.8096 - val_loss: 1.1852 - val_acc: 0.8066\n",
            "lr 0.04862684276952181 b1 0.6396875348678882 b2 0.9641528204389789 n_hiddens 336 batch_size 154 embedding_dim 297 en_dropout 0.3454672501989144 de_dropout 0.011447366627501177\n",
            "Epoch 1/10\n",
            "410/410 [==============================] - 36s 68ms/step - loss: 2.0250 - acc: 0.7346 - val_loss: 1.4690 - val_acc: 0.7614\n",
            "Epoch 2/10\n",
            "410/410 [==============================] - 25s 61ms/step - loss: 1.3711 - acc: 0.7789 - val_loss: 1.4103 - val_acc: 0.7802\n",
            "Epoch 3/10\n",
            "410/410 [==============================] - 26s 63ms/step - loss: 1.3285 - acc: 0.7851 - val_loss: 1.4063 - val_acc: 0.7870\n",
            "Epoch 4/10\n",
            "410/410 [==============================] - 27s 66ms/step - loss: 1.3032 - acc: 0.7876 - val_loss: 1.4261 - val_acc: 0.7844\n",
            "Epoch 5/10\n",
            "410/410 [==============================] - 26s 64ms/step - loss: 1.3137 - acc: 0.7878 - val_loss: 1.4847 - val_acc: 0.7856\n",
            "Epoch 6/10\n",
            "410/410 [==============================] - 25s 61ms/step - loss: 1.3207 - acc: 0.7884 - val_loss: 1.4932 - val_acc: 0.7845\n",
            "lr 0.009356619761583062 b1 0.5332853760659995 b2 0.7985972254756912 n_hiddens 421 batch_size 60 embedding_dim 157 en_dropout 0.42917553109835965 de_dropout 0.360774491217183\n",
            "Epoch 1/10\n",
            "1050/1050 [==============================] - 52s 44ms/step - loss: 1.2394 - acc: 0.8083 - val_loss: 1.0283 - val_acc: 0.8401\n",
            "Epoch 2/10\n",
            "1050/1050 [==============================] - 45s 43ms/step - loss: 1.0212 - acc: 0.8424 - val_loss: 0.9933 - val_acc: 0.8477\n",
            "Epoch 3/10\n",
            "1050/1050 [==============================] - 44s 42ms/step - loss: 0.9743 - acc: 0.8471 - val_loss: 0.9738 - val_acc: 0.8507\n",
            "Epoch 4/10\n",
            "1050/1050 [==============================] - 45s 43ms/step - loss: 0.9512 - acc: 0.8493 - val_loss: 0.9908 - val_acc: 0.8514\n",
            "Epoch 5/10\n",
            "1050/1050 [==============================] - 45s 43ms/step - loss: 0.9812 - acc: 0.8477 - val_loss: 0.9939 - val_acc: 0.8522\n",
            "Epoch 6/10\n",
            "1050/1050 [==============================] - 44s 42ms/step - loss: 0.9266 - acc: 0.8508 - val_loss: 0.9483 - val_acc: 0.8567\n",
            "Epoch 7/10\n",
            "1050/1050 [==============================] - 45s 42ms/step - loss: 0.8982 - acc: 0.8552 - val_loss: 0.9917 - val_acc: 0.8564\n",
            "Epoch 8/10\n",
            "1050/1050 [==============================] - 44s 42ms/step - loss: 0.9093 - acc: 0.8561 - val_loss: 1.0104 - val_acc: 0.8599\n",
            "Epoch 9/10\n",
            "1050/1050 [==============================] - 44s 42ms/step - loss: 0.8996 - acc: 0.8576 - val_loss: 1.0145 - val_acc: 0.8573\n",
            "lr 0.0457281561797704 b1 0.5076710156515364 b2 0.5199289398437946 n_hiddens 165 batch_size 225 embedding_dim 129 en_dropout 0.1406144712333035 de_dropout 0.45555442338770247\n",
            "Epoch 1/10\n",
            "280/280 [==============================] - 25s 68ms/step - loss: 1.4679 - acc: 0.7771 - val_loss: 1.2018 - val_acc: 0.8130\n",
            "Epoch 2/10\n",
            "280/280 [==============================] - 16s 58ms/step - loss: 1.2358 - acc: 0.8104 - val_loss: 1.2081 - val_acc: 0.8154\n",
            "Epoch 3/10\n",
            "280/280 [==============================] - 16s 59ms/step - loss: 1.2749 - acc: 0.8106 - val_loss: 1.2691 - val_acc: 0.8141\n",
            "Epoch 4/10\n",
            "280/280 [==============================] - 16s 58ms/step - loss: 1.3564 - acc: 0.8092 - val_loss: 1.3323 - val_acc: 0.8130\n",
            "lr 0.01679811924217257 b1 0.9959429750827256 b2 0.7594863749500774 n_hiddens 231 batch_size 502 embedding_dim 267 en_dropout 0.3497943935602377 de_dropout 0.1712040816938234\n",
            "Epoch 1/10\n",
            "126/126 [==============================] - 24s 133ms/step - loss: 12.2860 - acc: 0.6638 - val_loss: 65.2469 - val_acc: 0.5983\n",
            "Epoch 2/10\n",
            "126/126 [==============================] - 14s 112ms/step - loss: 734.9335 - acc: 0.3042 - val_loss: 2500.8958 - val_acc: 0.1876\n",
            "Epoch 3/10\n",
            "126/126 [==============================] - 14s 114ms/step - loss: 7291.9438 - acc: 0.3178 - val_loss: 14923.3516 - val_acc: 0.2686\n",
            "Epoch 4/10\n",
            "126/126 [==============================] - 14s 113ms/step - loss: 20190.1211 - acc: 0.1384 - val_loss: 14675.0283 - val_acc: 0.1471\n",
            "lr 0.09265086317330892 b1 0.8800318284057217 b2 0.9425648260243342 n_hiddens 8 batch_size 292 embedding_dim 202 en_dropout 0.00891600351209293 de_dropout 0.2948899342456032\n",
            "Epoch 1/10\n",
            "216/216 [==============================] - 24s 71ms/step - loss: 2.0993 - acc: 0.6928 - val_loss: 1.6373 - val_acc: 0.7355\n",
            "Epoch 2/10\n",
            "216/216 [==============================] - 12s 54ms/step - loss: 1.6070 - acc: 0.7368 - val_loss: 1.5688 - val_acc: 0.7426\n",
            "Epoch 3/10\n",
            "216/216 [==============================] - 12s 54ms/step - loss: 1.5582 - acc: 0.7400 - val_loss: 1.5364 - val_acc: 0.7451\n",
            "Epoch 4/10\n",
            "216/216 [==============================] - 12s 55ms/step - loss: 1.5304 - acc: 0.7425 - val_loss: 1.5176 - val_acc: 0.7467\n",
            "Epoch 5/10\n",
            "216/216 [==============================] - 12s 55ms/step - loss: 1.5162 - acc: 0.7437 - val_loss: 1.5163 - val_acc: 0.7467\n",
            "Epoch 6/10\n",
            "216/216 [==============================] - 13s 60ms/step - loss: 1.5076 - acc: 0.7443 - val_loss: 1.5129 - val_acc: 0.7472\n",
            "Epoch 7/10\n",
            "216/216 [==============================] - 13s 58ms/step - loss: 1.5031 - acc: 0.7446 - val_loss: 1.5112 - val_acc: 0.7485\n",
            "Epoch 8/10\n",
            "216/216 [==============================] - 12s 56ms/step - loss: 1.5001 - acc: 0.7445 - val_loss: 1.5187 - val_acc: 0.7474\n",
            "Epoch 9/10\n",
            "216/216 [==============================] - 12s 56ms/step - loss: 1.4978 - acc: 0.7449 - val_loss: 1.5133 - val_acc: 0.7478\n",
            "Epoch 10/10\n",
            "216/216 [==============================] - 12s 58ms/step - loss: 1.4959 - acc: 0.7449 - val_loss: 1.5237 - val_acc: 0.7474\n",
            "lr 0.08068888142242694 b1 0.6897667126065324 b2 0.6593224222592495 n_hiddens 495 batch_size 387 embedding_dim 157 en_dropout 0.09281511616558086 de_dropout 0.09893348002157276\n",
            "Epoch 1/10\n",
            "163/163 [==============================] - 35s 174ms/step - loss: 4.2851 - acc: 0.6987 - val_loss: 1.6232 - val_acc: 0.7527\n",
            "Epoch 2/10\n",
            "163/163 [==============================] - 26s 162ms/step - loss: 1.5616 - acc: 0.7601 - val_loss: 1.5860 - val_acc: 0.7614\n",
            "Epoch 3/10\n",
            "163/163 [==============================] - 26s 158ms/step - loss: 1.5456 - acc: 0.7668 - val_loss: 1.5965 - val_acc: 0.7720\n",
            "Epoch 4/10\n",
            "163/163 [==============================] - 26s 158ms/step - loss: 1.5534 - acc: 0.7738 - val_loss: 1.6337 - val_acc: 0.7736\n",
            "Epoch 5/10\n",
            "163/163 [==============================] - 26s 159ms/step - loss: 1.5835 - acc: 0.7752 - val_loss: 1.6768 - val_acc: 0.7743\n",
            "lr 0.09368401832374376 b1 0.6441522779323736 b2 0.7202581827799663 n_hiddens 147 batch_size 304 embedding_dim 154 en_dropout 0.1984830083082012 de_dropout 0.09426206797341496\n",
            "Epoch 1/10\n",
            "208/208 [==============================] - 31s 97ms/step - loss: 1.6601 - acc: 0.7458 - val_loss: 1.4539 - val_acc: 0.7706\n",
            "Epoch 2/10\n",
            "208/208 [==============================] - 16s 76ms/step - loss: 1.4491 - acc: 0.7717 - val_loss: 1.5041 - val_acc: 0.7694\n",
            "Epoch 3/10\n",
            "208/208 [==============================] - 16s 76ms/step - loss: 1.4806 - acc: 0.7734 - val_loss: 1.5496 - val_acc: 0.7717\n",
            "Epoch 4/10\n",
            "208/208 [==============================] - 15s 73ms/step - loss: 1.5147 - acc: 0.7747 - val_loss: 1.5977 - val_acc: 0.7703\n",
            "lr 0.042692283278584466 b1 0.6253716592985747 b2 0.5118043348713013 n_hiddens 55 batch_size 232 embedding_dim 221 en_dropout 0.2098795539821759 de_dropout 0.15286758968866554\n",
            "Epoch 1/10\n",
            "272/272 [==============================] - 26s 60ms/step - loss: 1.5628 - acc: 0.7640 - val_loss: 1.2489 - val_acc: 0.8026\n",
            "Epoch 2/10\n",
            "272/272 [==============================] - 14s 51ms/step - loss: 1.2165 - acc: 0.8077 - val_loss: 1.1931 - val_acc: 0.8108\n",
            "Epoch 3/10\n",
            "272/272 [==============================] - 13s 49ms/step - loss: 1.1813 - acc: 0.8128 - val_loss: 1.1857 - val_acc: 0.8127\n",
            "Epoch 4/10\n",
            "272/272 [==============================] - 14s 52ms/step - loss: 1.1783 - acc: 0.8132 - val_loss: 1.2055 - val_acc: 0.8120\n",
            "Epoch 5/10\n",
            "272/272 [==============================] - 14s 52ms/step - loss: 1.1949 - acc: 0.8126 - val_loss: 1.2465 - val_acc: 0.8093\n",
            "Epoch 6/10\n",
            "272/272 [==============================] - 15s 55ms/step - loss: 1.2098 - acc: 0.8117 - val_loss: 1.2694 - val_acc: 0.8091\n",
            "lr 0.024942993924761403 b1 0.816646713153006 b2 0.5758239227333691 n_hiddens 299 batch_size 345 embedding_dim 258 en_dropout 0.28320602438051407 de_dropout 0.006364671290011947\n",
            "Epoch 1/10\n",
            "183/183 [==============================] - 32s 118ms/step - loss: 1.8320 - acc: 0.7312 - val_loss: 1.4160 - val_acc: 0.7705\n",
            "Epoch 2/10\n",
            "183/183 [==============================] - 19s 106ms/step - loss: 1.3323 - acc: 0.7758 - val_loss: 1.3254 - val_acc: 0.7756\n",
            "Epoch 3/10\n",
            "183/183 [==============================] - 20s 108ms/step - loss: 1.2669 - acc: 0.7813 - val_loss: 1.3012 - val_acc: 0.7809\n",
            "Epoch 4/10\n",
            "183/183 [==============================] - 20s 108ms/step - loss: 1.2382 - acc: 0.7847 - val_loss: 1.2951 - val_acc: 0.7823\n",
            "Epoch 5/10\n",
            "183/183 [==============================] - 20s 108ms/step - loss: 1.2307 - acc: 0.7867 - val_loss: 1.3297 - val_acc: 0.7815\n",
            "Epoch 6/10\n",
            "183/183 [==============================] - 19s 105ms/step - loss: 1.2393 - acc: 0.7880 - val_loss: 1.3414 - val_acc: 0.7842\n",
            "Epoch 7/10\n",
            "183/183 [==============================] - 19s 107ms/step - loss: 1.2456 - acc: 0.7891 - val_loss: 1.3687 - val_acc: 0.7856\n",
            "lr 0.029361976229069386 b1 0.8722124105253817 b2 0.7990420122442797 n_hiddens 471 batch_size 127 embedding_dim 80 en_dropout 0.46692086319982246 de_dropout 0.424282790315655\n",
            "Epoch 1/10\n",
            "497/497 [==============================] - 44s 70ms/step - loss: 2.1539 - acc: 0.7357 - val_loss: 1.5056 - val_acc: 0.7663\n",
            "Epoch 2/10\n",
            "497/497 [==============================] - 32s 65ms/step - loss: 1.4992 - acc: 0.7694 - val_loss: 1.5014 - val_acc: 0.7733\n",
            "Epoch 3/10\n",
            "497/497 [==============================] - 32s 65ms/step - loss: 1.5303 - acc: 0.7730 - val_loss: 1.5535 - val_acc: 0.7763\n",
            "Epoch 4/10\n",
            "497/497 [==============================] - 32s 65ms/step - loss: 1.5718 - acc: 0.7737 - val_loss: 1.5835 - val_acc: 0.7772\n",
            "Epoch 5/10\n",
            "497/497 [==============================] - 32s 65ms/step - loss: 1.6382 - acc: 0.7732 - val_loss: 1.6622 - val_acc: 0.7770\n",
            "lr 0.015886169959430787 b1 0.5930491086706786 b2 0.9364600597831465 n_hiddens 312 batch_size 273 embedding_dim 166 en_dropout 0.1266038983112921 de_dropout 0.47534027805897144\n",
            "Epoch 1/10\n",
            "231/231 [==============================] - 30s 97ms/step - loss: 1.4377 - acc: 0.7726 - val_loss: 0.9330 - val_acc: 0.8339\n",
            "Epoch 2/10\n",
            "231/231 [==============================] - 20s 87ms/step - loss: 0.7914 - acc: 0.8508 - val_loss: 0.7378 - val_acc: 0.8631\n",
            "Epoch 3/10\n",
            "231/231 [==============================] - 20s 88ms/step - loss: 0.6159 - acc: 0.8744 - val_loss: 0.6561 - val_acc: 0.8763\n",
            "Epoch 4/10\n",
            "231/231 [==============================] - 20s 86ms/step - loss: 0.5213 - acc: 0.8871 - val_loss: 0.6221 - val_acc: 0.8813\n",
            "Epoch 5/10\n",
            "231/231 [==============================] - 20s 86ms/step - loss: 0.4640 - acc: 0.8944 - val_loss: 0.6002 - val_acc: 0.8846\n",
            "Epoch 6/10\n",
            "231/231 [==============================] - 20s 87ms/step - loss: 0.4263 - acc: 0.8991 - val_loss: 0.6023 - val_acc: 0.8859\n",
            "Epoch 7/10\n",
            "231/231 [==============================] - 20s 86ms/step - loss: 0.4004 - acc: 0.9024 - val_loss: 0.6051 - val_acc: 0.8852\n",
            "Epoch 8/10\n",
            "231/231 [==============================] - 20s 87ms/step - loss: 0.3837 - acc: 0.9042 - val_loss: 0.6089 - val_acc: 0.8865\n",
            "best_params [0.015886169959430787, 0.5930491086706786, 0.9364600597831465, 312, 273, 166, 0.1266038983112921, 0.47534027805897144]\n",
            "lr 0.05273769712037634 b1 0.771045744824429 b2 0.7738235870602771 n_hiddens 496 batch_size 72 embedding_dim 248 en_dropout 0.20062518730634193 de_dropout 0.09248141898419032\n",
            "Epoch 1/10\n",
            "875/875 [==============================] - 51s 51ms/step - loss: 1.8287 - acc: 0.7521 - val_loss: 1.8660 - val_acc: 0.7652\n",
            "Epoch 2/10\n",
            "875/875 [==============================] - 42s 47ms/step - loss: 1.9630 - acc: 0.7664 - val_loss: 2.0742 - val_acc: 0.7653\n",
            "Epoch 3/10\n",
            "875/875 [==============================] - 41s 47ms/step - loss: 2.1886 - acc: 0.7659 - val_loss: 2.3230 - val_acc: 0.7642\n",
            "Epoch 4/10\n",
            "875/875 [==============================] - 41s 47ms/step - loss: 2.4191 - acc: 0.7661 - val_loss: 2.5864 - val_acc: 0.7688\n",
            "lr 0.055601445446007314 b1 0.5916481064642332 b2 0.8536670972253568 n_hiddens 357 batch_size 176 embedding_dim 249 en_dropout 0.01406991540158703 de_dropout 0.39708082363877617\n",
            "Epoch 1/10\n",
            "358/358 [==============================] - 34s 78ms/step - loss: 1.5491 - acc: 0.7695 - val_loss: 1.3245 - val_acc: 0.7953\n",
            "Epoch 2/10\n",
            "358/358 [==============================] - 25s 70ms/step - loss: 1.3409 - acc: 0.7935 - val_loss: 1.3572 - val_acc: 0.7964\n",
            "Epoch 3/10\n",
            "358/358 [==============================] - 25s 70ms/step - loss: 1.3710 - acc: 0.7945 - val_loss: 1.3979 - val_acc: 0.7968\n",
            "Epoch 4/10\n",
            "358/358 [==============================] - 25s 70ms/step - loss: 1.4169 - acc: 0.7941 - val_loss: 1.4399 - val_acc: 0.7970\n",
            "lr 0.044215098079003395 b1 0.8786494412321751 b2 0.5257896988483647 n_hiddens 384 batch_size 454 embedding_dim 209 en_dropout 0.12885558872455527 de_dropout 0.020384087026159292\n",
            "Epoch 1/10\n",
            "139/139 [==============================] - 28s 156ms/step - loss: 4.2794 - acc: 0.6652 - val_loss: 4.4400 - val_acc: 0.7061\n",
            "Epoch 2/10\n",
            "139/139 [==============================] - 19s 140ms/step - loss: 4.0948 - acc: 0.7077 - val_loss: 3.9730 - val_acc: 0.7096\n",
            "Epoch 3/10\n",
            "139/139 [==============================] - 19s 138ms/step - loss: 4.0021 - acc: 0.7112 - val_loss: 4.0801 - val_acc: 0.7095\n",
            "Epoch 4/10\n",
            "139/139 [==============================] - 19s 135ms/step - loss: 4.6564 - acc: 0.6864 - val_loss: 4.6833 - val_acc: 0.6761\n",
            "Epoch 5/10\n",
            "139/139 [==============================] - 19s 134ms/step - loss: 5.1929 - acc: 0.7021 - val_loss: 5.6499 - val_acc: 0.6954\n",
            "lr 0.06399230927272871 b1 0.8022081836309816 b2 0.6193060601324336 n_hiddens 9 batch_size 429 embedding_dim 143 en_dropout 0.32337078773127215 de_dropout 0.19331651587228493\n",
            "Epoch 1/10\n",
            "147/147 [==============================] - 21s 85ms/step - loss: 2.7600 - acc: 0.5891 - val_loss: 2.1981 - val_acc: 0.7047\n",
            "Epoch 2/10\n",
            "147/147 [==============================] - 10s 68ms/step - loss: 1.9318 - acc: 0.7138 - val_loss: 1.7526 - val_acc: 0.7213\n",
            "Epoch 3/10\n",
            "147/147 [==============================] - 10s 69ms/step - loss: 1.6939 - acc: 0.7297 - val_loss: 1.6521 - val_acc: 0.7357\n",
            "Epoch 4/10\n",
            "147/147 [==============================] - 11s 72ms/step - loss: 1.6173 - acc: 0.7393 - val_loss: 1.5937 - val_acc: 0.7441\n",
            "Epoch 5/10\n",
            "147/147 [==============================] - 10s 69ms/step - loss: 1.5707 - acc: 0.7475 - val_loss: 1.5548 - val_acc: 0.7524\n",
            "Epoch 6/10\n",
            "147/147 [==============================] - 11s 72ms/step - loss: 1.5391 - acc: 0.7523 - val_loss: 1.5328 - val_acc: 0.7555\n",
            "Epoch 7/10\n",
            "147/147 [==============================] - 10s 69ms/step - loss: 1.5202 - acc: 0.7545 - val_loss: 1.5238 - val_acc: 0.7573\n",
            "Epoch 8/10\n",
            "147/147 [==============================] - 10s 69ms/step - loss: 1.5058 - acc: 0.7559 - val_loss: 1.5089 - val_acc: 0.7576\n",
            "Epoch 9/10\n",
            "147/147 [==============================] - 11s 72ms/step - loss: 1.4938 - acc: 0.7574 - val_loss: 1.5000 - val_acc: 0.7589\n",
            "Epoch 10/10\n",
            "147/147 [==============================] - 10s 68ms/step - loss: 1.4863 - acc: 0.7581 - val_loss: 1.5007 - val_acc: 0.7603\n",
            "lr 0.06915002475804598 b1 0.9260851442606486 b2 0.6656940653868313 n_hiddens 212 batch_size 507 embedding_dim 148 en_dropout 0.06237765532307099 de_dropout 0.20756265346428165\n",
            "Epoch 1/10\n",
            "125/125 [==============================] - 24s 128ms/step - loss: 3.0013 - acc: 0.6962 - val_loss: 3.7629 - val_acc: 0.7154\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 13s 108ms/step - loss: 3.5388 - acc: 0.7148 - val_loss: 3.2693 - val_acc: 0.7200\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 14s 110ms/step - loss: 3.5486 - acc: 0.7154 - val_loss: 3.3086 - val_acc: 0.7173\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 14s 110ms/step - loss: 3.8897 - acc: 0.7131 - val_loss: 3.5053 - val_acc: 0.7194\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 14s 109ms/step - loss: 4.2286 - acc: 0.7094 - val_loss: 4.1605 - val_acc: 0.7138\n",
            "lr 0.05438078409563382 b1 0.797069514311043 b2 0.8301929923331611 n_hiddens 191 batch_size 437 embedding_dim 112 en_dropout 0.02218607384415172 de_dropout 0.2345667169178683\n",
            "Epoch 1/10\n",
            "145/145 [==============================] - 25s 118ms/step - loss: 1.8315 - acc: 0.7221 - val_loss: 1.3374 - val_acc: 0.7713\n",
            "Epoch 2/10\n",
            "145/145 [==============================] - 15s 102ms/step - loss: 1.2338 - acc: 0.7848 - val_loss: 1.2122 - val_acc: 0.7924\n",
            "Epoch 3/10\n",
            "145/145 [==============================] - 15s 103ms/step - loss: 1.1584 - acc: 0.7955 - val_loss: 1.2064 - val_acc: 0.7968\n",
            "Epoch 4/10\n",
            "145/145 [==============================] - 15s 106ms/step - loss: 1.1330 - acc: 0.8000 - val_loss: 1.2036 - val_acc: 0.7991\n",
            "Epoch 5/10\n",
            "145/145 [==============================] - 15s 102ms/step - loss: 1.1174 - acc: 0.8031 - val_loss: 1.2183 - val_acc: 0.8012\n",
            "Epoch 6/10\n",
            "145/145 [==============================] - 15s 102ms/step - loss: 1.1152 - acc: 0.8047 - val_loss: 1.2330 - val_acc: 0.8017\n",
            "Epoch 7/10\n",
            "145/145 [==============================] - 15s 103ms/step - loss: 1.1137 - acc: 0.8055 - val_loss: 1.2429 - val_acc: 0.8024\n",
            "lr 0.033229711654843945 b1 0.6758362206652616 b2 0.5421071153171824 n_hiddens 474 batch_size 124 embedding_dim 175 en_dropout 0.2203264138955085 de_dropout 0.10858212483705315\n",
            "Epoch 1/10\n",
            "509/509 [==============================] - 43s 71ms/step - loss: 1.5089 - acc: 0.7781 - val_loss: 1.4467 - val_acc: 0.7902\n",
            "Epoch 2/10\n",
            "509/509 [==============================] - 33s 65ms/step - loss: 1.4814 - acc: 0.7914 - val_loss: 1.5569 - val_acc: 0.7892\n",
            "Epoch 3/10\n",
            "509/509 [==============================] - 33s 65ms/step - loss: 1.5894 - acc: 0.7877 - val_loss: 1.6942 - val_acc: 0.7818\n",
            "Epoch 4/10\n",
            "509/509 [==============================] - 33s 65ms/step - loss: 1.6896 - acc: 0.7866 - val_loss: 1.8069 - val_acc: 0.7849\n",
            "lr 0.09371685820879909 b1 0.6131284379504724 b2 0.8654584831833052 n_hiddens 271 batch_size 235 embedding_dim 127 en_dropout 0.06330525067808912 de_dropout 0.4253666884019714\n",
            "Epoch 1/10\n",
            "269/269 [==============================] - 31s 83ms/step - loss: 1.8972 - acc: 0.7443 - val_loss: 1.4226 - val_acc: 0.7778\n",
            "Epoch 2/10\n",
            "269/269 [==============================] - 20s 76ms/step - loss: 1.4256 - acc: 0.7794 - val_loss: 1.4321 - val_acc: 0.7801\n",
            "Epoch 3/10\n",
            "269/269 [==============================] - 20s 74ms/step - loss: 1.4442 - acc: 0.7806 - val_loss: 1.4782 - val_acc: 0.7803\n",
            "Epoch 4/10\n",
            "269/269 [==============================] - 20s 73ms/step - loss: 1.4776 - acc: 0.7801 - val_loss: 1.5299 - val_acc: 0.7829\n",
            "lr 0.02534581039601982 b1 0.9644285184515715 b2 0.9541757548488676 n_hiddens 395 batch_size 408 embedding_dim 154 en_dropout 0.4695161901310664 de_dropout 0.020722358810335628\n",
            "Epoch 1/10\n",
            "155/155 [==============================] - 32s 159ms/step - loss: 2.8059 - acc: 0.6562 - val_loss: 1.9671 - val_acc: 0.7274\n",
            "Epoch 2/10\n",
            "155/155 [==============================] - 22s 144ms/step - loss: 1.5823 - acc: 0.7502 - val_loss: 1.4475 - val_acc: 0.7652\n",
            "Epoch 3/10\n",
            "155/155 [==============================] - 22s 141ms/step - loss: 1.3072 - acc: 0.7746 - val_loss: 1.3300 - val_acc: 0.7802\n",
            "Epoch 4/10\n",
            "155/155 [==============================] - 22s 140ms/step - loss: 1.1962 - acc: 0.7825 - val_loss: 1.2911 - val_acc: 0.7821\n",
            "Epoch 5/10\n",
            "155/155 [==============================] - 22s 141ms/step - loss: 1.1338 - acc: 0.7872 - val_loss: 1.2679 - val_acc: 0.7851\n",
            "Epoch 6/10\n",
            "155/155 [==============================] - 22s 142ms/step - loss: 1.0902 - acc: 0.7910 - val_loss: 1.2587 - val_acc: 0.7853\n",
            "Epoch 7/10\n",
            "155/155 [==============================] - 22s 142ms/step - loss: 1.0599 - acc: 0.7939 - val_loss: 1.2562 - val_acc: 0.7906\n",
            "Epoch 8/10\n",
            "155/155 [==============================] - 22s 141ms/step - loss: 1.0367 - acc: 0.7959 - val_loss: 1.2608 - val_acc: 0.7905\n",
            "Epoch 9/10\n",
            "155/155 [==============================] - 22s 142ms/step - loss: 1.0128 - acc: 0.7990 - val_loss: 1.2467 - val_acc: 0.7916\n",
            "Epoch 10/10\n",
            "155/155 [==============================] - 22s 142ms/step - loss: 0.9887 - acc: 0.8021 - val_loss: 1.2456 - val_acc: 0.7970\n",
            "lr 0.017128197680272673 b1 0.9758117650440161 b2 0.9319366006289951 n_hiddens 236 batch_size 512 embedding_dim 95 en_dropout 0.40416444616136715 de_dropout 0.09073304852829539\n",
            "Epoch 1/10\n",
            "124/124 [==============================] - 24s 138ms/step - loss: 1.9817 - acc: 0.7106 - val_loss: 1.5866 - val_acc: 0.7512\n",
            "Epoch 2/10\n",
            "124/124 [==============================] - 14s 116ms/step - loss: 1.4751 - acc: 0.7630 - val_loss: 1.4215 - val_acc: 0.7699\n",
            "Epoch 3/10\n",
            "124/124 [==============================] - 14s 116ms/step - loss: 1.3033 - acc: 0.7764 - val_loss: 1.3351 - val_acc: 0.7777\n",
            "Epoch 4/10\n",
            "124/124 [==============================] - 14s 115ms/step - loss: 1.2057 - acc: 0.7836 - val_loss: 1.2881 - val_acc: 0.7835\n",
            "Epoch 5/10\n",
            "124/124 [==============================] - 14s 113ms/step - loss: 1.1418 - acc: 0.7889 - val_loss: 1.2639 - val_acc: 0.7844\n",
            "Epoch 6/10\n",
            "124/124 [==============================] - 14s 113ms/step - loss: 1.0979 - acc: 0.7924 - val_loss: 1.2459 - val_acc: 0.7876\n",
            "Epoch 7/10\n",
            "124/124 [==============================] - 14s 115ms/step - loss: 1.0623 - acc: 0.7959 - val_loss: 1.2376 - val_acc: 0.7891\n",
            "Epoch 8/10\n",
            "124/124 [==============================] - 14s 115ms/step - loss: 1.0305 - acc: 0.7984 - val_loss: 1.2266 - val_acc: 0.7891\n",
            "Epoch 9/10\n",
            "124/124 [==============================] - 14s 114ms/step - loss: 1.0091 - acc: 0.8002 - val_loss: 1.2260 - val_acc: 0.7913\n",
            "Epoch 10/10\n",
            "124/124 [==============================] - 14s 114ms/step - loss: 0.9892 - acc: 0.8027 - val_loss: 1.2158 - val_acc: 0.7926\n",
            "final best params [0.015886169959430787, 0.5930491086706786, 0.9364600597831465, 312, 273, 166, 0.1266038983112921, 0.47534027805897144]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Final LSTM model**\n",
        "\n",
        "Based on best hyperparameter from hyperparameter tuning process, we build our final LSTM model with them. "
      ],
      "metadata": {
        "id": "yJk8zfZUvwwQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# learning rate, b1, b2, hidden_units, batch_size, embedding_dim, encoder dropout, decoder dropout\n",
        "print('final best params',best_params)\n",
        "LSTM_final_lr = best_params[0]\n",
        "LSTM_final_b1 = best_params[1]\n",
        "LSTM_final_b2 = best_params[2]\n",
        "hidden_units = best_params[3]\n",
        "LSTM_final_batch = best_params[4]\n",
        "embedding_dim = best_params[5]\n",
        "LSTM_final_enD = best_params[6]\n",
        "LSTM_final_deD = best_params[7]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2OcnXDk2j-O",
        "outputId": "707f0b7a-cf6b-4e8c-fc47-f39a09b05d12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "final best params [0.015886169959430787, 0.5930491086706786, 0.9364600597831465, 312, 273, 166, 0.1266038983112921, 0.47534027805897144]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **LSTM evaluation**\n",
        "\n",
        "In NMT, there are diverse evaluation metrics from human evaluation methods to automatic evaluation metrics [??]. Here, we use some automatic evaluation metrics for evaluating our nmt model's performance.\n",
        "\n",
        "**For Lexical Similarity**\n",
        "\n",
        "* BLEU Score\n",
        "\n",
        "BLEU is based on the degree of n-gram overlapping between the strings of words produced by the machine and the human translation references at the corpus level. BLEU computes the precision for n-gram of size 1-to-4 with\n",
        "the coefficient of brevity penalty (BP).\n",
        "\n",
        "* ROUGE Score\n",
        "\n",
        "* Mete\n",
        "\n",
        "**For Linguistic Features**"
      ],
      "metadata": {
        "id": "NPuApOfs2w3A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoder\n",
        "encoder_inputs = Input(shape=(None,))\n",
        "enc_emb = Embedding(src_vocab_size, embedding_dim)(encoder_inputs) # Embedding layer\n",
        "enc_masking = Masking(mask_value=0.0)(enc_emb) # Exclude padding 0 in operation\n",
        "encoder_lstm = LSTM(hidden_units, return_state=True) # To return state value\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(enc_masking) # Return hidden state and cell state\n",
        "encoder_states = [state_h, state_c] # Save encoder's hidden state and cell state\n",
        "\n",
        "# Decoder\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "dec_emb_layer = Embedding(tar_vocab_size, hidden_units) # Embedding layer\n",
        "dec_emb = dec_emb_layer(decoder_inputs) # exclude padding 0 in operation\n",
        "dec_masking = Masking(mask_value=0.0)(dec_emb)\n",
        "\n",
        "# To return state value, return_state = True\n",
        "# To predict word for every time step, return_sequences = True\n",
        "decoder_lstm = LSTM(hidden_units, return_sequences=True, return_state=True) \n",
        "\n",
        "# Use encoder's hidden state as initial hidden state \n",
        "decoder_outputs, _, _ = decoder_lstm(dec_masking,\n",
        "                                     initial_state=encoder_states)\n",
        "\n",
        "# predict word bsaed on softmax activation function for all results from every time step\n",
        "decoder_dense = Dense(tar_vocab_size, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Model's input and output \n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "model.compile(optimizer=optimizers.Adam(learning_rate=LSTM_final_lr, beta_1=LSTM_final_b1, beta_2=LSTM_final_b2), \n",
        "              loss='sparse_categorical_crossentropy', metrics=['acc'])\n",
        "\n",
        "model_weights_path = './gdrive/MyDrive/AI/teamProject/LSTM/weights/weights.ckpt'\n",
        "\n",
        "save_best_weights = ModelCheckpoint(\n",
        "  model_weights_path, monitor='val_loss', mode='min',\n",
        "  save_weights_only=True, save_best_only=True, verbose=1, \n",
        ")\n",
        "\n",
        "history = model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train, \\\n",
        "        validation_data=([encoder_input_test, decoder_input_test], decoder_target_test),\n",
        "        batch_size=LSTM_final_batch, callbacks=[save_best_weights,EarlyStopping(monitor='val_loss', patience = 10)], epochs=50) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QXSULWUUfEc",
        "outputId": "f35acc81-896c-4fd4-f5cc-0fd85cb20e4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "231/231 [==============================] - ETA: 0s - loss: 1.4450 - acc: 0.7705\n",
            "Epoch 1: val_loss improved from inf to 0.95634, saving model to ./gdrive/MyDrive/AI/teamProject/LSTM/weights/weights.ckpt\n",
            "231/231 [==============================] - 30s 93ms/step - loss: 1.4450 - acc: 0.7705 - val_loss: 0.9563 - val_acc: 0.8297\n",
            "Epoch 2/50\n",
            "231/231 [==============================] - ETA: 0s - loss: 0.8016 - acc: 0.8484\n",
            "Epoch 2: val_loss improved from 0.95634 to 0.77351, saving model to ./gdrive/MyDrive/AI/teamProject/LSTM/weights/weights.ckpt\n",
            "231/231 [==============================] - 20s 86ms/step - loss: 0.8016 - acc: 0.8484 - val_loss: 0.7735 - val_acc: 0.8564\n",
            "Epoch 3/50\n",
            "231/231 [==============================] - ETA: 0s - loss: 0.6150 - acc: 0.8735\n",
            "Epoch 3: val_loss improved from 0.77351 to 0.69534, saving model to ./gdrive/MyDrive/AI/teamProject/LSTM/weights/weights.ckpt\n",
            "231/231 [==============================] - 20s 86ms/step - loss: 0.6150 - acc: 0.8735 - val_loss: 0.6953 - val_acc: 0.8682\n",
            "Epoch 4/50\n",
            "231/231 [==============================] - ETA: 0s - loss: 0.5044 - acc: 0.8889\n",
            "Epoch 4: val_loss improved from 0.69534 to 0.65631, saving model to ./gdrive/MyDrive/AI/teamProject/LSTM/weights/weights.ckpt\n",
            "231/231 [==============================] - 20s 85ms/step - loss: 0.5044 - acc: 0.8889 - val_loss: 0.6563 - val_acc: 0.8748\n",
            "Epoch 5/50\n",
            "231/231 [==============================] - ETA: 0s - loss: 0.4333 - acc: 0.8989\n",
            "Epoch 5: val_loss improved from 0.65631 to 0.65041, saving model to ./gdrive/MyDrive/AI/teamProject/LSTM/weights/weights.ckpt\n",
            "231/231 [==============================] - 20s 88ms/step - loss: 0.4333 - acc: 0.8989 - val_loss: 0.6504 - val_acc: 0.8779\n",
            "Epoch 6/50\n",
            "231/231 [==============================] - ETA: 0s - loss: 0.3859 - acc: 0.9057\n",
            "Epoch 6: val_loss improved from 0.65041 to 0.64766, saving model to ./gdrive/MyDrive/AI/teamProject/LSTM/weights/weights.ckpt\n",
            "231/231 [==============================] - 20s 87ms/step - loss: 0.3859 - acc: 0.9057 - val_loss: 0.6477 - val_acc: 0.8788\n",
            "Epoch 7/50\n",
            "231/231 [==============================] - ETA: 0s - loss: 0.3518 - acc: 0.9103\n",
            "Epoch 7: val_loss did not improve from 0.64766\n",
            "231/231 [==============================] - 20s 86ms/step - loss: 0.3518 - acc: 0.9103 - val_loss: 0.6552 - val_acc: 0.8786\n",
            "Epoch 8/50\n",
            "231/231 [==============================] - ETA: 0s - loss: 0.3270 - acc: 0.9141\n",
            "Epoch 8: val_loss did not improve from 0.64766\n",
            "231/231 [==============================] - 20s 86ms/step - loss: 0.3270 - acc: 0.9141 - val_loss: 0.6638 - val_acc: 0.8787\n",
            "Epoch 9/50\n",
            "231/231 [==============================] - ETA: 0s - loss: 0.3095 - acc: 0.9170\n",
            "Epoch 9: val_loss did not improve from 0.64766\n",
            "231/231 [==============================] - 20s 86ms/step - loss: 0.3095 - acc: 0.9170 - val_loss: 0.6743 - val_acc: 0.8800\n",
            "Epoch 10/50\n",
            "231/231 [==============================] - ETA: 0s - loss: 0.2959 - acc: 0.9192\n",
            "Epoch 10: val_loss did not improve from 0.64766\n",
            "231/231 [==============================] - 20s 88ms/step - loss: 0.2959 - acc: 0.9192 - val_loss: 0.6858 - val_acc: 0.8801\n",
            "Epoch 11/50\n",
            "231/231 [==============================] - ETA: 0s - loss: 0.2849 - acc: 0.9215\n",
            "Epoch 11: val_loss did not improve from 0.64766\n",
            "231/231 [==============================] - 20s 86ms/step - loss: 0.2849 - acc: 0.9215 - val_loss: 0.6978 - val_acc: 0.8795\n",
            "Epoch 12/50\n",
            "231/231 [==============================] - ETA: 0s - loss: 0.2778 - acc: 0.9226\n",
            "Epoch 12: val_loss did not improve from 0.64766\n",
            "231/231 [==============================] - 20s 87ms/step - loss: 0.2778 - acc: 0.9226 - val_loss: 0.7161 - val_acc: 0.8785\n",
            "Epoch 13/50\n",
            "231/231 [==============================] - ETA: 0s - loss: 0.2716 - acc: 0.9238\n",
            "Epoch 13: val_loss did not improve from 0.64766\n",
            "231/231 [==============================] - 20s 86ms/step - loss: 0.2716 - acc: 0.9238 - val_loss: 0.7236 - val_acc: 0.8791\n",
            "Epoch 14/50\n",
            "231/231 [==============================] - ETA: 0s - loss: 0.2668 - acc: 0.9245\n",
            "Epoch 14: val_loss did not improve from 0.64766\n",
            "231/231 [==============================] - 20s 87ms/step - loss: 0.2668 - acc: 0.9245 - val_loss: 0.7412 - val_acc: 0.8782\n",
            "Epoch 15/50\n",
            "231/231 [==============================] - ETA: 0s - loss: 0.2635 - acc: 0.9253\n",
            "Epoch 15: val_loss did not improve from 0.64766\n",
            "231/231 [==============================] - 20s 86ms/step - loss: 0.2635 - acc: 0.9253 - val_loss: 0.7502 - val_acc: 0.8768\n",
            "Epoch 16/50\n",
            "231/231 [==============================] - ETA: 0s - loss: 0.2615 - acc: 0.9257\n",
            "Epoch 16: val_loss did not improve from 0.64766\n",
            "231/231 [==============================] - 20s 86ms/step - loss: 0.2615 - acc: 0.9257 - val_loss: 0.7591 - val_acc: 0.8781\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoder\n",
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "# Decoder \n",
        "# Tensor for previous step's state \n",
        "decoder_state_input_h = Input(shape=(hidden_units,))\n",
        "decoder_state_input_c = Input(shape=(hidden_units,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "# Reuse Embedding layer that was used in training phase \n",
        "dec_emb2 = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "# To predict next word.. \n",
        "# Previous time step's state -> current time step's initial state  \n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\n",
        "decoder_states2 = [state_h2, state_c2]\n",
        "\n",
        "# Predict word in every time step \n",
        "decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
        "\n",
        "# Updated decoder \n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + decoder_states_inputs,\n",
        "    [decoder_outputs2] + decoder_states2)"
      ],
      "metadata": {
        "id": "lBppG7vpUsFr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # 입력으로부터 인코더의 마지막 시점의 상태(은닉 상태, 셀 상태)를 얻음\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "    \n",
        "    # <SOS>에 해당하는 정수 생성\n",
        "    target_seq = np.zeros((1,1))\n",
        "    target_seq[0, 0] = tar_to_index['<sos>']\n",
        "    \n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    \n",
        "    # Iterate loop until stop_condition becomes True\n",
        "    # 구현의 간소화를 위해서 이 함수는 배치 크기를 1로 가정합니다.\n",
        "    \n",
        "    while not stop_condition:\n",
        "        # 이점 시점의 상태 states_value를 현 시점의 초기 상태로 사용\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "        \n",
        "        # 예측 결과를 단어로 변환\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = index_to_tar[sampled_token_index]\n",
        "        \n",
        "        # 현재 시점의 예측 단어를 예측 문장에 추가\n",
        "        decoded_sentence += ' '+sampled_char\n",
        "        \n",
        "        # <eos>에 도달하거나 정해진 길이를 넘으면 중단.\n",
        "        if (sampled_char == '<eos>' or len(decoded_sentence) > 50):\n",
        "            stop_condition = True\n",
        "            \n",
        "        # 현재 시점의 예측 결과를 다음 시점의 입력으로 사용하기 위해 저장\n",
        "        target_seq = np.zeros((1,1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "        \n",
        "        # 현재 시점의 상태를 다음 시점의 상태로 사용하기 위해 저장\n",
        "        states_value = [h, c]\n",
        "        \n",
        "    return decoded_sentence"
      ],
      "metadata": {
        "id": "oRu34aJ-WA_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# transform original sentence's integer sequence to text sequence \n",
        "def seq_to_src(input_seq):\n",
        "    sentence = ''\n",
        "    for encoded_word in input_seq:\n",
        "        if(encoded_word != 0):\n",
        "            sentence = sentence + index_to_src[encoded_word] + ' '\n",
        "    return sentence\n",
        "\n",
        "# transform translated sentence's integer sequence to text sequence\n",
        "def seq_to_tar(input_seq):\n",
        "    sentence = ''\n",
        "    for encoded_word in input_seq:\n",
        "        if(encoded_word != 0 and encoded_word != tar_to_index['<sos>'] and encoded_word != tar_to_index['<eos>']):\n",
        "            sentence = sentence + index_to_tar[encoded_word] + ' '\n",
        "            \n",
        "    return sentence"
      ],
      "metadata": {
        "id": "Ap2hb1M9XNzT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for seq_index in [3, 50, 100, 300, 1001]:\n",
        "    input_seq = encoder_input_train[seq_index: seq_index + 1]\n",
        "    print(input_seq)\n",
        "    decoded_sentence = decode_sequence(input_seq)\n",
        "    \n",
        "    print(\"입력문장 :\",seq_to_src(encoder_input_train[seq_index]))\n",
        "    print(\"정답문장 :\",seq_to_tar(decoder_input_train[seq_index]))\n",
        "    print(\"번역문장 :\",decoded_sentence[1:-5])\n",
        "    print(\"-\"*50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gnWII0PR_3Fd",
        "outputId": "b29b62bd-0d79-4bac-ce4c-032aa570b37e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 21   3  33 136   4   0   0   0   0]]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 80ms/step\n",
            "1/1 [==============================] - 0s 86ms/step\n",
            "1/1 [==============================] - 0s 78ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "입력문장 : are you all ready ? \n",
            "정답문장 : etes vous tous prets ? \n",
            "번역문장 : etes vous toutes dingues ? \n",
            "--------------------------------------------------\n",
            "[[  2 634 336 280 305   1   0   0   0]]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "입력문장 : i drank beer last night . \n",
            "정답문장 : j ai bu de la biere la nuit derniere . \n",
            "번역문장 : j ai la biere pour la biere . \n",
            "--------------------------------------------------\n",
            "[[   8    9    5 2103  157    1    0    0    0]]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "입력문장 : it s a sunny day . \n",
            "정답문장 : c est un jour ensoleille . \n",
            "번역문장 : c est une journee journee . \n",
            "--------------------------------------------------\n",
            "[[  2  17  92  12 544   1   0   0   0]]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "입력문장 : i m going to fight . \n",
            "정답문장 : je vais me battre . \n",
            "번역문장 : je vais etre prudente . \n",
            "--------------------------------------------------\n",
            "[[   3   13 1931    1    0    0    0    0    0]]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "입력문장 : you re unambitious . \n",
            "정답문장 : tu es depourvu d ambition . \n",
            "번역문장 : vous etes depourvu d ambition . \n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "일부 환경에서 완전한 입력-목표 시퀀스 쌍을 버퍼링할 수 없듯이(예를 들어, 만약 매우 긴 시퀀스는 online 학습) 이는 전체 목표 시퀀스로 접근할 수 없기 때문에 Teacher forcing을 사용할 수 없습니다. 이 경우 decoder의 예측값을 입력으로 재입력하여 학습을 실행할 수 있습니다. (그저 추론될 수 있도록)\n",
        "\n",
        "출력값을 재주입하는 루프를 설계한 모델을 구축하면 다음과 같은 결과를 얻을 수 있습니다.\n",
        "\n",
        "위와 같이 입력을 Ground Truth로 넣어주게 되면,\n",
        "\n",
        "학습시 더 정확한 예측이 가능하게 되기 때문에\n",
        "\n",
        "초기 학습 속도를 빠르게 올릴 수 있다."
      ],
      "metadata": {
        "id": "uJMJXchK-cf7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **GRU model**"
      ],
      "metadata": {
        "id": "2PLmPlcOBZMs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Hyperparameter Selection Process**\n",
        "\n",
        "With Random Search"
      ],
      "metadata": {
        "id": "Po1h0yz4BeKa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, Embedding, GRU\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.utils import plot_model"
      ],
      "metadata": {
        "id": "uCMHzm945gNu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_train_model(\n",
        "  enc_seqlen, dec_seqlen, enc_vocabsize, dec_vocabsize, hsize, \n",
        "  embsize, encoder_dropout, decoder_dropout):\n",
        "  ### Encoder\n",
        "  encoder_inputs = Input(shape=(None,), name=\"encoder_input\")\n",
        "  embedding = Embedding(\n",
        "      enc_vocabsize, embsize, name=\"encoder_embedding\"\n",
        "  )\n",
        "  encoder_gru = GRU(\n",
        "      hsize, return_state=True, name=\"encoder_gru\", dropout=encoder_dropout\n",
        "  )\n",
        "  encoder_emb = embedding(encoder_inputs)\n",
        "  encoder_outputs, encoder_state = encoder_gru(encoder_emb)\n",
        "\n",
        "  ### Decoder\n",
        "  decoder_inputs = Input(shape=(None,), name=\"decoder_input\")\n",
        "  embedding = Embedding(\n",
        "      dec_vocabsize, embsize, input_length=dec_seqlen-1, name=\"decoder_embedding\"\n",
        "   )\n",
        "  decoder_gru = GRU(\n",
        "      hsize, return_state=True, return_sequences=True, name=\"decoder_gru\", \n",
        "      dropout=decoder_dropout\n",
        "  )\n",
        "\n",
        "  decoder_emb = embedding(decoder_inputs)\n",
        "  decoder_outputs, _ = decoder_gru(decoder_emb, initial_state=encoder_state)\n",
        "  dense_layer = Dense(dec_vocabsize, activation=\"softmax\", name=\"dense_layer\")\n",
        "  decoder_outputs = dense_layer(decoder_outputs)\n",
        "\n",
        "  # Define the Model which accepts encoder/decoder inputs and outputs predictions\n",
        "  model = Model(\n",
        "      inputs=[encoder_inputs, decoder_inputs],\n",
        "      outputs=decoder_outputs,\n",
        "      name=\"encoder_decoder_model_gru\",\n",
        "  )\n",
        "  return model"
      ],
      "metadata": {
        "id": "ZiTeUevlhxuz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def GRU_Model(embedding_dim, hidden_units, lr, b1, b2, batchsize, encoder_dropout, decoder_dropout):\n",
        "  model = create_train_model(\n",
        "    src_seqlen, tar_seqlen, src_vocab_size, tar_vocab_size, \n",
        "    hidden_units, embedding_dim, \n",
        "    encoder_dropout, decoder_dropout\n",
        "  )\n",
        "\n",
        "  model.compile(optimizer=optimizers.Adam(learning_rate=lr, beta_1=b1, beta_2=b2), loss='sparse_categorical_crossentropy', metrics=['acc'])\n",
        "\n",
        "  history = model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train, \\\n",
        "          validation_data=([encoder_input_test, decoder_input_test], decoder_target_test),\n",
        "          batch_size=batchsize, callbacks=[EarlyStopping(monitor='val_loss', patience = 3)], epochs=10) # for testing, we use epochs = 10 \n",
        "\n",
        "\n",
        "  return history.history['val_loss'][-1]"
      ],
      "metadata": {
        "id": "RPseZEYj5iDo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_hyper_param(n_iteration):\n",
        "  hyper_param = []  # learning_rate, n_hidden, timestep, epochs\n",
        "  for i in range(n_iteration):\n",
        "    current_params = []\n",
        "    # We use adam optimizer, so we tune learning rate\n",
        "    current_params.append(np.random.uniform(0,0.1)) # learning rate \n",
        "    current_params.append(np.random.uniform(0.5,0.999)) # b1 (from Momentum)\n",
        "    current_params.append(np.random.uniform(0.5,0.999)) # b2 (from RMSProp)\n",
        "    current_params.append(np.random.randint(1,513)) # hidden units \n",
        "    current_params.append(np.random.randint(32,513)) # batch_size\n",
        "    current_params.append(np.random.randint(50,300)) # embedding dimension\n",
        "    current_params.append(np.random.uniform(0,0.5)) # encoder dropout\n",
        "    current_params.append(np.random.uniform(0,0.5)) # decoder dropout\n",
        "    hyper_param.append(current_params)\n",
        "  return hyper_param\n",
        "\n",
        "hyper_parameter = get_hyper_param(30)\n",
        "train_loss, val_loss = list(), list()\n",
        "best_params_gru = []\n",
        "\n",
        "min_val_loss = 999\n",
        "for alpha, b1, b2, hidden_units, batch_size, embedding_dim, en_dropout, de_dropout in hyper_parameter:\n",
        "  print('lr',alpha, 'b1', b1, 'b2', b2, 'n_hiddens', hidden_units,'batch_size', batch_size, 'embedding_dim', embedding_dim, \n",
        "        'en_dropout',  en_dropout, 'de_dropout', de_dropout)\n",
        "\n",
        "  # model 정의 (model.add ~ model.compile 까지)\n",
        "  current_val_loss = GRU_Model(embedding_dim, hidden_units, alpha, b1, b2, batch_size, en_dropout, de_dropout)\n",
        "\n",
        "  if current_val_loss < min_val_loss:\n",
        "    min_val_loss = current_val_loss\n",
        "    best_params = [alpha, b1, b2, hidden_units, batch_size, embedding_dim, en_dropout, de_dropout]\n",
        "    print('best_params',best_params_gru)\n",
        "  \n",
        "print('final best params',best_params_gru)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tHVi_IiC2050",
        "outputId": "b937311c-869b-45f9-d494-5ce00e36d40f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lr 0.08282658244015961 b1 0.571573182981131 b2 0.8968709386260224 n_hiddens 394 batch_size 118 embedding_dim 211 en_dropout 0.37457963135095734 de_dropout 0.4368113816473733\n",
            "Epoch 1/10\n",
            "534/534 [==============================] - 29s 48ms/step - loss: 7.5421 - acc: 0.7012 - val_loss: 8.3749 - val_acc: 0.7068\n",
            "Epoch 2/10\n",
            "534/534 [==============================] - 25s 47ms/step - loss: 8.8152 - acc: 0.7130 - val_loss: 9.1793 - val_acc: 0.7228\n",
            "Epoch 3/10\n",
            "534/534 [==============================] - 26s 49ms/step - loss: 9.5562 - acc: 0.7138 - val_loss: 9.9835 - val_acc: 0.7214\n",
            "Epoch 4/10\n",
            "534/534 [==============================] - 26s 48ms/step - loss: 10.0048 - acc: 0.7136 - val_loss: 10.6554 - val_acc: 0.7164\n",
            "best_params []\n",
            "lr 0.08309691041604804 b1 0.6028145592359843 b2 0.6755410399211511 n_hiddens 226 batch_size 134 embedding_dim 199 en_dropout 0.42543102589446546 de_dropout 0.12908943716723353\n",
            "Epoch 1/10\n",
            "471/471 [==============================] - 24s 44ms/step - loss: 2.4718 - acc: 0.7476 - val_loss: 2.1736 - val_acc: 0.7707\n",
            "Epoch 2/10\n",
            "471/471 [==============================] - 20s 42ms/step - loss: 2.0960 - acc: 0.7781 - val_loss: 2.0988 - val_acc: 0.7820\n",
            "Epoch 3/10\n",
            "471/471 [==============================] - 20s 43ms/step - loss: 2.0184 - acc: 0.7858 - val_loss: 2.1080 - val_acc: 0.7866\n",
            "Epoch 4/10\n",
            "471/471 [==============================] - 20s 43ms/step - loss: 2.0415 - acc: 0.7901 - val_loss: 2.1758 - val_acc: 0.7933\n",
            "Epoch 5/10\n",
            "471/471 [==============================] - 20s 43ms/step - loss: 2.0766 - acc: 0.7931 - val_loss: 2.2122 - val_acc: 0.7926\n",
            "best_params []\n",
            "lr 0.051380312215114 b1 0.8965962282907183 b2 0.6276511413133588 n_hiddens 511 batch_size 259 embedding_dim 241 en_dropout 0.4456315555752475 de_dropout 0.3853522988050699\n",
            "Epoch 1/10\n",
            "244/244 [==============================] - 25s 91ms/step - loss: 30.1058 - acc: 0.6757 - val_loss: 63.3921 - val_acc: 0.6874\n",
            "Epoch 2/10\n",
            "244/244 [==============================] - 21s 88ms/step - loss: 77.9943 - acc: 0.6941 - val_loss: 73.5724 - val_acc: 0.6994\n",
            "Epoch 3/10\n",
            "244/244 [==============================] - 22s 89ms/step - loss: 80.9201 - acc: 0.6980 - val_loss: 70.0496 - val_acc: 0.7127\n",
            "Epoch 4/10\n",
            "244/244 [==============================] - 22s 90ms/step - loss: 76.1332 - acc: 0.6992 - val_loss: 68.3979 - val_acc: 0.7106\n",
            "lr 0.015048674338124714 b1 0.5755907419330111 b2 0.6846933186630839 n_hiddens 283 batch_size 128 embedding_dim 131 en_dropout 0.03793114202108061 de_dropout 0.4941940844495001\n",
            "Epoch 1/10\n",
            "493/493 [==============================] - 25s 45ms/step - loss: 1.2704 - acc: 0.8066 - val_loss: 1.0296 - val_acc: 0.8377\n",
            "Epoch 2/10\n",
            "493/493 [==============================] - 21s 43ms/step - loss: 1.0188 - acc: 0.8421 - val_loss: 1.0079 - val_acc: 0.8443\n",
            "Epoch 3/10\n",
            "493/493 [==============================] - 22s 44ms/step - loss: 0.9913 - acc: 0.8477 - val_loss: 1.0030 - val_acc: 0.8467\n",
            "Epoch 4/10\n",
            "385/493 [======================>.......] - ETA: 4s - loss: 0.9827 - acc: 0.8474"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-116-26035d805817>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m   \u001b[0;31m# model 정의 (model.add ~ model.compile 까지)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m   \u001b[0mcurrent_val_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGRU_Model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_units\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0men_dropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mde_dropout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mcurrent_val_loss\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mmin_val_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-113-4e1ba4587327>\u001b[0m in \u001b[0;36mGRU_Model\u001b[0;34m(embedding_dim, hidden_units, lr, b1, b2, batchsize, encoder_dropout, decoder_dropout)\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta_1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta_2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sparse_categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m   history = model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train, \\\n\u001b[0m\u001b[1;32m     11\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mencoder_input_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_input_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_target_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m           batch_size=batchsize, callbacks=[EarlyStopping(monitor='val_loss', patience = 3)], epochs=10) # for testing, we use epochs = 10 \n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1407\u001b[0m                 _r=1):\n\u001b[1;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1410\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2451\u001b[0m       (graph_function,\n\u001b[1;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2454\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1859\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1860\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1861\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    498\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Final GRU model**"
      ],
      "metadata": {
        "id": "fb2WyGduD5CG"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r3ip0M3a_PT3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_weights_path = './gdrive/MyDrive/AI/teamProject/GRU/weights/weights.ckpt'"
      ],
      "metadata": {
        "id": "7NM11NmPIb3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_best_weights = tf.keras.callbacks.ModelCheckpoint(\n",
        "  model_weights_path, monitor='val_loss', mode='min',\n",
        "  save_weights_only=True, save_best_only=True, verbose=1, \n",
        ")\n",
        "\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "  monitor='val_loss', patience=2, verbose=1,\n",
        "  mode='min', restore_best_weights=True, \n",
        ")"
      ],
      "metadata": {
        "id": "ECX6T2hgIJRX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_inference_encoder_from(input_layer, embedding_layer, gru_layer):\n",
        "  encoder_embedding = embedding_layer(input_layer)\n",
        "  encoder_outputs, encoder_state = gru_layer(encoder_embedding)\n",
        "  encoder = Model(input_layer, encoder_state)\n",
        "  return encoder\n",
        "\n",
        "def create_inference_decoder_from(input_layer, embedding_layer, gru_layer, dense_layer):\n",
        "  # decoder_input = Input(shape=(1,))\n",
        "  decoder_embedding = embedding_layer(input_layer)\n",
        "  input_shape = dense_layer.input.shape[-1]\n",
        "  decoder_inputs_state = Input(shape=(input_shape,))\n",
        "\n",
        "  decoder_output, decoder_output_state = gru_layer(\n",
        "    decoder_embedding, initial_state=decoder_inputs_state\n",
        "  )\n",
        "\n",
        "  decoder_prediction = dense_layer(decoder_output)\n",
        "  decoder = Model(\n",
        "    inputs=[input_layer, decoder_inputs_state], \n",
        "    outputs=[decoder_prediction, decoder_output_state]\n",
        "  )\n",
        "  return decoder"
      ],
      "metadata": {
        "id": "qO92pTyzD9IJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = create_inference_encoder_from(\n",
        "  model.get_layer('encoder_input').input,\n",
        "  model.get_layer('encoder_embedding'),\n",
        "  model.get_layer('encoder_gru')\n",
        ")\n",
        "\n",
        "decoder = create_inference_decoder_from(\n",
        "  model.get_layer('decoder_input').input,\n",
        "  model.get_layer('decoder_embedding'),\n",
        "  model.get_layer('decoder_gru'),\n",
        "  model.get_layer('dense_layer'),\n",
        ")"
      ],
      "metadata": {
        "id": "dBROLhPAEIeW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # 입력으로부터 인코더의 마지막 시점의 상태(은닉 상태, 셀 상태)를 얻음\n",
        "    state = encoder.predict(input_seq)\n",
        "    \n",
        "    # <SOS>에 해당하는 정수 생성\n",
        "    target_seq = np.zeros((1,1))\n",
        "    target_seq[0, 0] = tar_to_index['<sos>']\n",
        "    \n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    \n",
        "    # stop_condition이 True가 될 때까지 루프 반복\n",
        "    # 구현의 간소화를 위해서 이 함수는 배치 크기를 1로 가정합니다.\n",
        "    \n",
        "    while not stop_condition:\n",
        "        # 이점 시점의 상태 states_value를 현 시점의 초기 상태로 사용\n",
        "        output_tokens, state = decoder.predict([target_seq, state])\n",
        "        \n",
        "        # 예측 결과를 단어로 변환\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = index_to_tar[sampled_token_index]\n",
        "        \n",
        "        # 현재 시점의 예측 단어를 예측 문장에 추가\n",
        "        decoded_sentence += ' '+sampled_char\n",
        "        \n",
        "        # <eos>에 도달하거나 정해진 길이를 넘으면 중단.\n",
        "        if (sampled_char == '<eos>' or len(decoded_sentence) > 50):\n",
        "            stop_condition = True\n",
        "            \n",
        "        # 현재 시점의 예측 결과를 다음 시점의 입력으로 사용하기 위해 저장\n",
        "        target_seq = np.zeros((1,1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "        \n",
        "        # # 현재 시점의 상태를 다음 시점의 상태로 사용하기 위해 저장\n",
        "        state = [state]\n",
        "        \n",
        "    return decoded_sentence"
      ],
      "metadata": {
        "id": "SYfeWyjdEMAv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Predicted Result & Evaluation**\n",
        "\n",
        "### Evaluation Metrics\n",
        "We use same evaluation metrics in LSTM"
      ],
      "metadata": {
        "id": "APNeSEp6SlOh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk.translate.bleu_score as bleu\n",
        "from rouge import Rouge"
      ],
      "metadata": {
        "id": "1dvVYV_iVs5J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rouge = Rouge()\n",
        "\n",
        "for seq_index in [3, 50, 100, 300, 1001]:\n",
        "    reference = [[]]\n",
        "    candidate = []\n",
        "    input_seq = encoder_input_train[seq_index: seq_index + 1]\n",
        "    decoded_sentence = decode_sequence(input_seq)\n",
        "    \n",
        "\n",
        "    input_sentence = seq_to_src(encoder_input_train[seq_index])\n",
        "    answer_sentence = seq_to_tar(decoder_input_train[seq_index])\n",
        "    translated_sentence = decoded_sentence[1:-5]\n",
        "\n",
        "    print(\"Input Sentence :\", input_sentence)\n",
        "    print(\"Answer Sentence: \", answer_sentence)\n",
        "    print(\"Translated Sentence :\", translated_sentence)\n",
        "\n",
        "    print(rouge.get_scores([translated_sentence], [answer_sentence], avg=True))\n",
        "    reference[0].extend(answer_sentence.split())\n",
        "    candidate.extend(translated_sentence.split())\n",
        "    print('BLEU score: {:.5f}'.format(bleu.sentence_bleu(reference, candidate, weights=(1.0, 0, 0, 0))))\n",
        "    \n",
        "    print(\"-\"*50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0n0KH_3AEOTQ",
        "outputId": "ab6fe70b-a277-497d-a593-049ee387a883"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Input Sentence : i like busy places . \n",
            "Answer Sentence:  j aime les endroits debordant d activite . \n",
            "Translated Sentence : j aime les endroits debordant d activite . \n",
            "{'rouge-1': {'r': 1.0, 'p': 1.0, 'f': 0.999999995}, 'rouge-2': {'r': 1.0, 'p': 1.0, 'f': 0.999999995}, 'rouge-l': {'r': 1.0, 'p': 1.0, 'f': 0.999999995}}\n",
            "BLEU score: 1.00000\n",
            "--------------------------------------------------\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "Input Sentence : i m always careful . \n",
            "Answer Sentence:  je suis toujours prudent . \n",
            "Translated Sentence : je suis toujours prudent . \n",
            "{'rouge-1': {'r': 1.0, 'p': 1.0, 'f': 0.999999995}, 'rouge-2': {'r': 1.0, 'p': 1.0, 'f': 0.999999995}, 'rouge-l': {'r': 1.0, 'p': 1.0, 'f': 0.999999995}}\n",
            "BLEU score: 1.00000\n",
            "--------------------------------------------------\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "Input Sentence : you re a filthy liar ! \n",
            "Answer Sentence:  vous etes une sale menteuse ! \n",
            "Translated Sentence : tu es un sale menteur ! \n",
            "{'rouge-1': {'r': 0.3333333333333333, 'p': 0.3333333333333333, 'f': 0.3333333283333334}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.3333333333333333, 'p': 0.3333333333333333, 'f': 0.3333333283333334}}\n",
            "BLEU score: 0.33333\n",
            "--------------------------------------------------\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.8/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.8/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Input Sentence : no one seems to know . \n",
            "Answer Sentence:  personne ne semble savoir . \n",
            "Translated Sentence : personne ne semble savoir . \n",
            "{'rouge-1': {'r': 1.0, 'p': 1.0, 'f': 0.999999995}, 'rouge-2': {'r': 1.0, 'p': 1.0, 'f': 0.999999995}, 'rouge-l': {'r': 1.0, 'p': 1.0, 'f': 0.999999995}}\n",
            "BLEU score: 1.00000\n",
            "--------------------------------------------------\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Input Sentence : it s quiet . \n",
            "Answer Sentence:  c est calme . \n",
            "Translated Sentence : c est calme . \n",
            "{'rouge-1': {'r': 1.0, 'p': 1.0, 'f': 0.999999995}, 'rouge-2': {'r': 1.0, 'p': 1.0, 'f': 0.999999995}, 'rouge-l': {'r': 1.0, 'p': 1.0, 'f': 0.999999995}}\n",
            "BLEU score: 1.00000\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Teacher Forcing\n",
        "\n",
        "* Technique where the target word is passed as the next input to the decoder \n",
        "\n",
        "\n",
        "t-1번째에서 정확한 예측이 이루어졌다면 상관없지만,\n",
        "\n",
        "잘못된 예측이 이루어졌다면 t번째 디코더의 추론 역시 잘못된 예측으로 이어질 것이다.\n",
        "\n",
        "이전 예측을 고려해주는 디코더의 장점이 \n",
        "\n",
        "잘못된 예측 앞에서는 엄청난 단점이 되어버린다.\n",
        "\n",
        "특히 이러한 단점은 학습 초기에 학습 속도 저하의 요인이 된다.\n",
        "\n",
        "이러한 단점을 해결하기 위해 나온 기법이 티쳐포싱(Teacher Forcing) 기법이다.\n",
        "\n",
        "장 단점\n",
        "장점: 학습 빠름\n",
        "단점: 노출 편향 문제"
      ],
      "metadata": {
        "id": "pJ5i3U27CYyD"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hTG7MDuD-ACk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Final Result and Insights**"
      ],
      "metadata": {
        "id": "tp2GbEBYCjTB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **References**\n",
        "\n",
        "[??] Han, Lifeng. \"Machine translation evaluation resources and methods: A survey.\" arXiv preprint arXiv:1605.04515 (2016)."
      ],
      "metadata": {
        "id": "pe68r1Q1EYcI"
      }
    }
  ]
}